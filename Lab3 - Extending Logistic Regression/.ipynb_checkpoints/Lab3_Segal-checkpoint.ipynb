{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Matan Segal\n",
    "\n",
    "## Life is Too Short to Drink Cheap Wine\n",
    "\n",
    "#### Business understanding\n",
    "\n",
    "The dataset token from: https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009 \n",
    "\n",
    "Originally, it was posted on the UCI machine learning repository: https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "\n",
    "Citation: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n",
    "\n",
    "The dataset related to red variants of the Portuguese \"Vinho Verde\" wine. It contains 1599 different wines, which each have the following 11 features: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, and alcohol percentage. The target of the set is the quality of the wine, which is on scale of 0 to 10 (0 is very poor and 10 is an excellent wine). The measurement of the target was measured by sensors, which require several tests in a special lab and most importantly can be made just after making the wine.\n",
    " \n",
    "The model I am claiming to build should use the features given to predict the quality of a wine before making it. the classification task is the scale of quality from 0 to 10. Based on the model, the wine producer should provide the required features for making the wine, and the model will return the predicted quality of the wine that will be made. Using the model, the producer will not need to wait until the end of the process of making the wine in order to measure the quality of the wine, but they will have a prediction even before starting the process. \n",
    "\n",
    "The parties which will be interested in such a model will be the red wine producers as well as the wine stores that will be able to have a tool to measure the quality of the wine without the lab testing process. \n",
    "\n",
    "For the model to be useful, it should have accuracy of at least 90%. In this case, the producers should use the model before the process of making the wine in order to set the features for best results, and at the end still make a quality checking for more accurate results.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prapering the Data\n",
    "\n",
    "##### Data representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('winequality-red.csv', encoding='unicode_escape', low_memory=True) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have no missing data and that all of our values are numeric values that we can use for our training data as well as for tesing the data. I will use all the first 11 features for the data and the 'quality' column for the target. However, I will take the target and change it to one-hot encoding..  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1599, 11)\n",
      "Unique values in Y: [3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "X = (df.T[:11]).T\n",
    "print('X shape:',X.shape)\n",
    "Y_ = df['quality']\n",
    "print('Unique values in Y:',np.unique(Y_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the quality column, we can see that there are actually values from 3 to 8, so our classification will be amoung 6 classes.\n",
    "\n",
    "Now, I will check how many time each unique value appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 : 10\n",
      "4 : 53\n",
      "5 : 681\n",
      "6 : 638\n",
      "7 : 199\n",
      "8 : 18\n"
     ]
    }
   ],
   "source": [
    "qualityList = [3, 4, 5, 6, 7, 8]\n",
    "for i in range(6):\n",
    "    print(qualityList[i],':',(df[df['quality'] == qualityList[i]]).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since qulity level 3 and 8 barely showed up, I will take them off and update X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df new shape: (1571, 12)\n",
      "X shape: (1571, 11)\n",
      "Unique values in Y: [4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "df = df[~df['quality'].isin([3,8])]\n",
    "print('df new shape:',df.shape)\n",
    "X = (df.T[:11]).T\n",
    "print('X shape:',X.shape)\n",
    "Y = df['quality']\n",
    "print('Unique values in Y:',np.unique(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1256, 11)\n",
      "X_test shape: (315, 11)\n",
      "Y_train shape: (1256,)\n",
      "Y_test shape: (315,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('Y_train shape:',Y_train.shape)\n",
    "print('Y_test shape:',Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test:\n",
      "4 : 11\n",
      "5 : 127\n",
      "6 : 129\n",
      "7 : 48\n",
      "\n",
      "Y_train\n",
      "4 : 42\n",
      "5 : 554\n",
      "6 : 509\n",
      "7 : 151\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "Y_train_1enc = pd.get_dummies(Y_train).values\n",
    "Y_test_1enc = pd.get_dummies(Y_test).values\n",
    "\n",
    "# counts values in Y train and test to see how many unique values\n",
    "qualityList = [4, 5, 6, 7]\n",
    "print('Y_test:')\n",
    "for col in range(4):\n",
    "    print(qualityList[col],':',sum(Y_test_1enc[:,col]))\n",
    "    \n",
    "print('\\nY_train')\n",
    "for col in range(4):\n",
    "    print(qualityList[col],':',sum(Y_train_1enc[:,col]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both, Y_train and Y_test we have approximation of normal distribution of the quality level. The test and the train sizes are acceptable for building a model and test it. In addition, the features used for prediction in the data are independent on one another and independent from raw to raw, therefore we can say that dividing our data into 20/80 precatage ratio is appropriate for my data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Steepest Descent, Stochastic Gradient Descent, Newton's method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of:  0.5015873015873016\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "class BinaryLR: \n",
    "    # private:\n",
    "    def __init__(self, eta, iterations = 20, C = 0.001, Reg = 'no',optTec = 'steepDes'):\n",
    "        # optTech = optimization techinque [steepDes,SDG,newtons]\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.reg = Reg\n",
    "        self.ot = optTec\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    def _get_gradient(self,X,y):\n",
    "        # choose between the three\n",
    "        \n",
    "        if (self.ot == 'steepDes'):\n",
    "            ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "            gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "            return gradient.reshape(self.w_.shape)\n",
    "        \n",
    "        elif (self.ot == 'SDG'):\n",
    "            idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "            ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "            gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "            gradient = gradient.reshape(self.w_.shape)\n",
    "            gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "            return gradient\n",
    "        \n",
    "        elif (self.ot == 'newtons'): \n",
    "            g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
    "            hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n",
    "            ydiff = y-g # get y difference\n",
    "            gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "            gradient = gradient.reshape(self.w_.shape)\n",
    "            gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "            return pinv(hessian) @ gradient\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self, X, add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "\n",
    "    def fitBinary(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape  \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros  \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate\n",
    "            # adding the regularization terms:\n",
    "            if(self.reg == 'L1' or self.reg == 'L1L2'):\n",
    "                self.w_[1:] -=self.eta*2*self.C*self.w_[1:] # update not include bias\n",
    "            if(self.reg == 'L2' or self.reg == 'L1L2'):\n",
    "                self.w_[1:] -=self.eta*self.C*abs(self.w_[1:])\n",
    "\n",
    "class LR(BinaryLR):\n",
    "    \n",
    "    def __init__(self, eta, iterations = 20, C = 0.001, Reg = 'no', optTec = 'steepDes'):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.reg = Reg\n",
    "        self.ot = optTec\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = (y==yval) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = BinaryLR(self.eta,self.iters,self.C,self.reg,self.ot)\n",
    "            blr.fitBinary(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row\n",
    "    \n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# testing the class:\n",
    "# optTech = optimization techinque [steepDes,SDG,newtons]\n",
    "\n",
    "lr = LR(0.001, 100, C=0.01, Reg = 'L1',optTec = 'steepDes')\n",
    "lr.fit(X_train,Y_train)\n",
    "yhat = lr.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(Y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One layer Neural Network (I added it because I thought it can be used as steepest desending, but it performed worse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of:  0.40634920634920635\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class NerualNet1:\n",
    "    def __init__(self, eta, iterations = 20, C = 0.001, Reg = 'no'):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.reg = Reg\n",
    "        \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.vstack((np.ones((1,X.shape[1])),X)) # add bias term as a row\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # using one layer neural network\n",
    "    def _get_gradient(self,X,y):\n",
    "        yhat = self.predict_proba(X,add_bias=False) #yhat is the predicted value (= A2)\n",
    "        V = (-2*(y - yhat)) * yhat * (1-yhat)  \n",
    "        return V @ X.T\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(self.w_ @ Xb) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        A = X.T\n",
    "        return self.unique_[np.argmax(self.predict_proba(A)>0.5,axis=0)]\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.unique_ = np.unique(y)\n",
    "        y = pd.get_dummies(y).values\n",
    "        y = y.T\n",
    "        A = X.T # make these as sets of columns samples\n",
    "        A = self._add_bias(A) # add bias term       \n",
    "        num_features = A.shape[0]\n",
    "        num_elems = y.shape[0]\n",
    "        \n",
    "        self.w_ = np.zeros((num_elems,num_features)) # init weight vector to zeros\n",
    "        \n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(A,y)\n",
    "            self.w_ -= gradient*self.eta # multiply by learning rate \n",
    "            if(self.reg == 'L1' or self.reg == 'L1L2'):\n",
    "                self.w_[1:] -=self.eta*2*self.C*self.w_[1:] # update not include bias\n",
    "            if(self.reg == 'L2' or self.reg == 'L1L2'):\n",
    "                self.w_[1:] -=self.eta*self.C*abs(self.w_[1:])\n",
    "            \n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "lr = NerualNet1(eta=0.05,iterations=200,C=0.01,Reg = 'L2')\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "yhat = lr.predict(X_test)\n",
    "\n",
    "print('Accuracy of: ',accuracy_score(Y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will write a function that will ask the user the kind of optimization technique as well as regularization type and the values of eta, iterations and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LogisticRegression(X_train,Y_train,X_test,Y_test,eta, iterations = 20, C = 0.01, Reg = 'no', optTech = 'steepDes'):\n",
    "    # Reg = regularization [no,L1,L2,L1L2]\n",
    "    # optTech = optimization techinque [steepDes,SDG,newtons,1NN] , where 1NN is one layer neural network\n",
    "    lr = 0\n",
    "    if(optTech == 'steepDes' or optTech == 'SDG' or optTech == 'newtons'):\n",
    "        lr = LR(eta, iterations, C,Reg, optTech)\n",
    "    elif(optTech == '1NN'):\n",
    "        lr = NerualNet1(eta, iterations, C,Reg)\n",
    "    else:\n",
    "        print('Wrong input')\n",
    "        return\n",
    "    \n",
    "    lr.fit(X_train,Y_train)\n",
    "    yhat = lr.predict(X_test)\n",
    "    return accuracy_score(Y_test,yhat)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing several results from running all the optimizations techmiques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steepDes     50.16 %.\n",
      "SDG          44.13 %.\n",
      "newtons      54.92 %.\n",
      "NN1          40.32 %.\n"
     ]
    }
   ],
   "source": [
    "tecList = ['steepDes','SDG']\n",
    "\n",
    "for tec in tecList:\n",
    "    acc = LogisticRegression(X_train,Y_train,X_test,Y_test,\n",
    "                                          0.001, 100, C = 0.01, \n",
    "                                          Reg = 'L1', optTech = tec)\n",
    "    print('{:10s} {:7.2f} %.'.format(tec, acc * 100))\n",
    "    \n",
    "acc = LogisticRegression(X_train,Y_train,X_test,Y_test,\n",
    "                                          0.001, 5, C = 0.01, \n",
    "                                          Reg = 'L1L2', optTech = 'newtons')\n",
    "print('{:10s} {:7.2f} %.'.format('newtons', acc * 100)) \n",
    "\n",
    "acc = LogisticRegression(X_train,Y_train,X_test,Y_test,\n",
    "                                          0.1, 100, C = 0.01, \n",
    "                                          Reg = 'L2', optTech = '1NN')\n",
    "print('{:10s} {:7.2f} %.'.format('NN1', acc * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best performance on the data is by the Newton's method.In order to check best performance overall, I will check for each one its performance with different values for eta and iters. For Newton's methos I will use small number of iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------- steepDes ------------------\n",
      "eta = 0.0001, iter =    5 , acc = 40.32 %.\n",
      "eta = 0.0001, iter =   20 , acc = 40.32 %.\n",
      "eta = 0.0001, iter =  100 , acc = 41.90 %.\n",
      "eta = 0.0001, iter =  250 , acc = 46.98 %.\n",
      "eta = 0.0010, iter =    5 , acc = 40.63 %.\n",
      "eta = 0.0010, iter =   20 , acc = 43.49 %.\n",
      "eta = 0.0010, iter =  100 , acc = 50.16 %.\n",
      "eta = 0.0010, iter =  250 , acc = 49.52 %.\n",
      "eta = 0.0100, iter =    5 , acc = 40.63 %.\n",
      "eta = 0.0100, iter =   20 , acc = 40.95 %.\n",
      "eta = 0.0100, iter =  100 , acc = 23.49 %.\n",
      "eta = 0.0100, iter =  250 , acc = 39.37 %.\n",
      "eta = 0.1000, iter =    5 , acc = 46.03 %.\n",
      "eta = 0.1000, iter =   20 , acc = 13.97 %.\n",
      "eta = 0.1000, iter =  100 , acc = 15.56 %.\n",
      "eta = 0.1000, iter =  250 , acc = 9.21 %.\n",
      "eta = 1.0000, iter =    5 , acc = 41.90 %.\n",
      "eta = 1.0000, iter =   20 , acc = 21.27 %.\n",
      "eta = 1.0000, iter =  100 , acc = 29.84 %.\n",
      "eta = 1.0000, iter =  250 , acc = 18.73 %.\n",
      "\n",
      "----------------- SDG ------------------\n",
      "eta = 0.0001, iter =    5 , acc = 40.32 %.\n",
      "eta = 0.0001, iter =   20 , acc = 40.32 %.\n",
      "eta = 0.0001, iter =  100 , acc = 40.32 %.\n",
      "eta = 0.0001, iter =  250 , acc = 40.32 %.\n",
      "eta = 0.0010, iter =    5 , acc = 40.32 %.\n",
      "eta = 0.0010, iter =   20 , acc = 40.32 %.\n",
      "eta = 0.0010, iter =  100 , acc = 48.89 %.\n",
      "eta = 0.0010, iter =  250 , acc = 40.32 %.\n",
      "eta = 0.0100, iter =    5 , acc = 40.32 %.\n",
      "eta = 0.0100, iter =   20 , acc = 40.00 %.\n",
      "eta = 0.0100, iter =  100 , acc = 18.73 %.\n",
      "eta = 0.0100, iter =  250 , acc = 43.17 %.\n",
      "eta = 0.1000, iter =    5 , acc = 40.32 %.\n",
      "eta = 0.1000, iter =   20 , acc = 15.24 %.\n",
      "eta = 0.1000, iter =  100 , acc = 29.21 %.\n",
      "eta = 0.1000, iter =  250 , acc = 39.37 %.\n",
      "eta = 1.0000, iter =    5 , acc = 34.29 %.\n",
      "eta = 1.0000, iter =   20 , acc = 42.54 %.\n",
      "eta = 1.0000, iter =  100 , acc = 40.32 %.\n",
      "eta = 1.0000, iter =  250 , acc = 40.32 %.\n",
      "\n",
      "----------------- 1NN ------------------\n",
      "eta = 0.0001, iter =    5 , acc = 3.49 %.\n",
      "eta = 0.0001, iter =   20 , acc = 40.32 %.\n",
      "eta = 0.0001, iter =  100 , acc = 40.32 %.\n",
      "eta = 0.0001, iter =  250 , acc = 12.38 %.\n",
      "eta = 0.0010, iter =    5 , acc = 31.43 %.\n",
      "eta = 0.0010, iter =   20 , acc = 10.79 %.\n",
      "eta = 0.0010, iter =  100 , acc = 17.78 %.\n",
      "eta = 0.0010, iter =  250 , acc = 21.27 %.\n",
      "eta = 0.0100, iter =    5 , acc = 40.00 %.\n",
      "eta = 0.0100, iter =   20 , acc = 39.68 %.\n",
      "eta = 0.0100, iter =  100 , acc = 39.68 %.\n",
      "eta = 0.0100, iter =  250 , acc = 39.68 %.\n",
      "eta = 0.1000, iter =    5 , acc = 40.32 %.\n",
      "eta = 0.1000, iter =   20 , acc = 40.32 %.\n",
      "eta = 0.1000, iter =  100 , acc = 40.32 %.\n",
      "eta = 0.1000, iter =  250 , acc = 40.32 %.\n",
      "eta = 1.0000, iter =    5 , acc = 40.00 %.\n",
      "eta = 1.0000, iter =   20 , acc = 37.78 %.\n",
      "eta = 1.0000, iter =  100 , acc = 3.49 %.\n",
      "eta = 1.0000, iter =  250 , acc = 3.49 %.\n",
      "\n",
      "----------------- newtons ------------------\n",
      "eta = 0.0001, iter =    2 , acc = 54.92 %.\n",
      "eta = 0.0001, iter =    4 , acc = 54.92 %.\n",
      "eta = 0.0001, iter =    6 , acc = 54.92 %.\n",
      "eta = 0.0001, iter =    8 , acc = 54.92 %.\n",
      "eta = 0.0010, iter =    2 , acc = 54.92 %.\n",
      "eta = 0.0010, iter =    4 , acc = 54.92 %.\n",
      "eta = 0.0010, iter =    6 , acc = 54.92 %.\n",
      "eta = 0.0010, iter =    8 , acc = 54.92 %.\n",
      "eta = 0.0100, iter =    2 , acc = 54.60 %.\n",
      "eta = 0.0100, iter =    4 , acc = 54.60 %.\n",
      "eta = 0.0100, iter =    6 , acc = 54.29 %.\n",
      "eta = 0.0100, iter =    8 , acc = 54.29 %.\n",
      "eta = 0.1000, iter =    2 , acc = 56.83 %.\n",
      "eta = 0.1000, iter =    4 , acc = 36.51 %.\n",
      "eta = 0.1000, iter =    6 , acc = 10.16 %.\n",
      "eta = 0.1000, iter =    8 , acc = 5.08 %.\n",
      "eta = 1.0000, iter =    2 , acc = 40.32 %.\n",
      "eta = 1.0000, iter =    4 , acc = 40.32 %.\n",
      "eta = 1.0000, iter =    6 , acc = 40.32 %.\n",
      "eta = 1.0000, iter =    8 , acc = 40.32 %.\n"
     ]
    }
   ],
   "source": [
    "tecList = ['steepDes','SDG','1NN','newtons']\n",
    "\n",
    "etaVals = [0.0001,0.001,0.01,0.1,1]\n",
    "iterVals = [5,20,100,250]\n",
    "newtoniter = [2,4,6,8]\n",
    "\n",
    "steepDesList = []\n",
    "SDGlist = []\n",
    "newtonList = []\n",
    "NN1List = []\n",
    "\n",
    "listList = [steepDesList,SDGlist,NN1List,newtonList]\n",
    "\n",
    "for o in range(3):\n",
    "    print('\\n-----------------',tecList[o],'------------------')\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "            acc = LogisticRegression(X_train,Y_train,X_test,Y_test,etaVals[i], \n",
    "                                     iterVals[j], C = 0.01, Reg = 'L1L2',  optTech = tecList[o])* 100\n",
    "            print('eta = {:5.4f}, iter = {:4d} , acc = {:3.2f} %.'.format(etaVals[i],iterVals[j], acc))\n",
    "            listList[o].append(acc)\n",
    "            \n",
    "# newton\n",
    "print('\\n-----------------',tecList[3],'------------------')\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        acc = LogisticRegression(X_train,Y_train,X_test,Y_test,etaVals[i], \n",
    "                                     newtoniter[j], C = 0.01, Reg = 'L1L2', optTech = tecList[3])* 100\n",
    "        print('eta = {:5.4f}, iter = {:4d} , acc = {:3.2f} %.'.format(etaVals[i],newtoniter[j], acc))\n",
    "        listList[3].append(acc)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAAE/CAYAAADhUuoDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydeZhcZZm376dr6TWdTifdIRBCNoQEkMUImCAiiqKi6CjK6My4gLgPAiow3zcDKrjMOCI6bsygZvBzwA110CiIgmxp9rBLFgIhK0l3SCep7q6uer4/3jrpptPVtZ06p071c19XX6fq1FneSupUnd/7exZRVQzDMAzDMAzDMIxo0hD2AAzDMAzDMAzDMIzyMVFnGIZhGIZhGIYRYUzUGYZhGIZhGIZhRBgTdYZhGIZhGIZhGBHGRJ1hGIZhGIZhGEaEMVFnGIZhGIZhGIYRYUzUGYZhGIZhGIZhRBgTdRFFRC4XkR8HdK4PiEhGRHbn/p4RkR+KyMuCOL9hRAEROUlE7haRF0WkV0TuEpFXFnv9iEhSRP5FRP4qIntEZKOIrBCRN4T1ngyj1hCRT4rI/SIyKCI/GrX+FBFREfn2mO3vFJEP5B5/ILfNZ8ds87yInBLA8A2jLsldVwvDHsdkx0SdUSz3qGobMBV4PZACHhCRI8MdlmGEj4i0AzcB3wI6gYOAzwODuU2KuX5+DpwJ/AMwDZgHXA28JYj3YBgRYRNwBfCDcV7bA/yDiMydYP9e4OLcNWsYhlE3mKiLACJycW7Wvj83i/8W4J+A9+Rm/lfltpsqIteKyObc9leISGzUcT4kIk+KSJ+I/EFEDhn1morIP4rIOhHZLiL/JiL7fT5UNaOqa1X148DtwOWjjnFizqnYKSKrRs985mZI1+XewzMi8r5q/FsZRki8DEBV/yd3jaRU9WZVfWT0RvmuHxF5PXAacKaq9qjqUO7v96p6fsDvxTBqFlX9par+Ctgxzss7gR8Bl01wiCeBe4AL/B+dYdQmIrJeRD4jIo/kokluEJGm3GtniMjDuXu3u0Xk5bn1HxSR/x11jDUi8tNRzzeIyDEi8pfcqlW5e9L35F7/cG6fXhH5jYgcOGpfFZGPisjq3D3pt0VEcq8tFJHbc+PcLiI3BPBPVBeYqKtxROQw4JPAK1V1CvBG4CngS8ANqtqmqkfnNl8ODAMLgWOBNwDn5o7zdpwQ/BugC7gD+J8xp3sHsAQ4DucYfKjA8H4JvDp3/IOA3+JmUDuBzwC/EJEuEWkFvgm8KfcelgIPl/yPYRi1y9NARkSWi8ibRGRaEfvsu35w7l2Pqj5ftREaxuTgSuCdud/OfPwzcIGIdAY0JsOoBd4NnI6LAnk58AEROQ7nen8EmA58H/iNiDTiJh5fLSINIjILSADLAERkPtAGPKKqJ+eOf3TunvQGETkV+HLunLOAZ4Hrx4znDOCVwNG57d6YW/9F4GZcxMpsXASMUQQm6mqfDNAILBaRhKquV9W1YzcSkZnAm4BPq+oeVd0GXAWcndvkI8CXVfVJVR3GicJjRrt1wFdVtVdVnwO+AfxtgbFtwgk4gL8Dfqeqv1PVrKreAtwPvDn3ehY4UkSaVXWzqj5e4r+DYdQsqroLOAlQ4D+BF3IzkzMn2G309TMD2OK9ICKduVnTF0VkoFrjNox6Q1W3AN8DvjDBNg/jbhovDmpchlEDfFNVN6lqL/C/wDHAh4Hv5yJEMqq6HJc2cKKqrgP6c9u9BvgDsFFEDs89v0NVs3nO9T7gB6r6oKoOApcCrxoTGv0VVd2Zu+f8c+48AGngEOBAVR1Q1Tt9+xeoc0zU1Tiqugb4NC5Ma5uIXD/awh7FIbhZlM25m8GduBmX7lGvXz3qtV5AcLk/HhtGPX4WGO88ozkodxzv+Gd5x8+d4yRglqruAd4DfDQ3vt/mvhQMo27ITZh8QFVnA0firp9vTLDL6OtnB2420ztWr6p2AK/ATeoYhlE8XwXeKCJHT7DNvwAfE5EDAhqTYYTNllGP9+KctkOAi8bcux3MyP3f7cApwMm5x7fhBN1rcs/zcSDuPhIAVd2N+50bfc853ngAPoe7P71XRB4XkUJRY0YOE3URQFV/oqon4S4+xf1g6ZjNNuBmV2aoakfur11Vjxj1+kdGvdahqs2qeveoYxw86vEcnJMwEe/AhXF6x79uzPFbVfUruffwB1U9DXfj+hTOzTCMukRVn8Ll9kxUSGj09XMr8EoRmV3loRlG3aOqO3ATKl+cYJuncCHQ/xTUuAyjBtkAXDnm3q1FVb30HE/UvTr3+HaKE3WbcPesAOTScKYDGwsNSFW3qOqHVfVAXJTZd8QqaxaFiboaR0QOE5FTc/HNA7iqeRlgKzDXK2aiqptx4ST/LiLtuRjoBSLymtyhvgdcKiJH5I47VUTOGnO6z4rINBE5GDgf2C85VURiIjJPRL6Fu9A/n3vpx8BbReSNuW2axJWYni0iM0XkbbmLehDYnXsPhlEXiMjhInKRJ8py19DfAivHbDfu9aOqN+PCT34lIieIa2+QAE4M8n0YRq0jIvFcgYcY4P3WxMfZ9Ou4/O1FExzu88AHgQ7/R2oYkeA/gY/mfndERFpF5C0iMiX3+u3Aa4HmXM73Hbi8vOnAQ6OOsxWYP+r5T4AP5gqpNOJSfnpUdX2hAYnIWaMmOPtwJobdMxaBibrapxH4CrAdZ1V342YWf5Z7fYeIPJh7/A9AEngCdyH8nFxIl6reiHP4rheRXcBjuBy80fwaeABXxOS3wLWjXnuViOwGduHs93Zc8ZZHc8ffgCuu8k/AC7jZn8/iPmMNwEW4mZte3AzPx8v/JzGMmqMfOAHoEZE9ODH3GO5zDwWunxx/g2uL8GNcFb9ncHkJpwfxBgwjIvxf3OTmJbhc7lRu3UvI5bn+KyN5q/uhqs8A1wGtVRmpYdQ4qno/Lq/uP3D3jWuAD4x6/WncRPwduee7gHXAXao6WmhdDizPhXC+W1VvxRUk+gWwGVjASI2HQrwS91u6G/gNcH7uWjUKIKpjo/iMyYiIKHBoLofPMAzDMAzDMIyIYE6dYRiGYRiGYRhGhDFRZxiGYRiGYRiGEWEs/NIwDMMwDMMwDCPCmFNnGIZhGIZhGIYRYUzUGYZhGIZhGIZhRJjxervUHDNmzNC5c+eGPQzD8JUHHnhgu6p2VXocEVmPK6mfAYZVdYmIdOL6DM4F1gPvVtW+iY5j15lRj/h1nfmJXWtGvWHXmWEEw0TXWiRE3dy5c7n//vvDHoZh+IqIPOvj4V6rqttHPb8EuFVVvyIil+SeXzzRAew6M+oRn68zX7Brzag37DozjGCY6Fqz8EvDqE/OBJbnHi8H3h7iWAzDMAzDMIwqYqLOMKKPAjeLyAMicl5u3UxV3QyQW3aHNjrDMAzDMAyjqkQi/NIwjAlZpqqbRKQbuEVEnip2x5wIPA9gzpw51RqfYRiGYRiGUUXMqTOMiKOqm3LLbcCNwPHAVhGZBZBbbsuz7zWqukRVl3R11VSOu2EYhmEYhlEkJuoMI8KISKuITPEeA28AHgN+A7w/t9n7gV+HM0LDMAzDMAyj2lj4pWFEm5nAjSIC7nr+iar+XkTuA34qIucAzwFnhThGwzAMwzAMo4qYqDOMCKOq64Cjx1m/A3hd8CMyDMMwDMMwgsbCLw3DMAzDMAzDMCJMVZ06EVkP9AMZYFhVl4hIJ3ADMBdYD7xbVfuqOQ7DMAzDMAzDMIx6JYjwy9eq6vZRzy8BblXVr4jIJbnnFwcwjmiwZw/86U/w+tdDc3PYozGMuuX222HJEmhtDXskRlQQkRhwP7BRVc8QkXnA9UAn8CDw96o6VM0xDGeH+dnjP2P30O4JtztsxmGcfMjJ1RzKpOSZvme49ZlbUdWqn6sp3sQJs0/g0M5DyeVNG8akQFXp67uZqVNPJhaze+FiCSOn7kzglNzj5cBtmKgb4dvfhosvhhkz4KMfhY9/HGbNCntUhlFXbN0Kr30tfP3r8OlPhz0aI0KcDzwJtOeefxW4SlWvF5HvAecA363mAO7ecDfv/eV7C27X3tjOi5e8WM2hTCpW71jNl+78Etetuo6MZgI996y2WZx8yMmcfMjJvOaQ17C4a7GJPKOu2bTpO6xe/UkOP/w6Djjg78IeTmSotqhT4GYRUeD7qnoNMFNVNwOo6uZcw+T9mLRNke++Gw46yFkIV14JX/0qnH02XHABHHts2KMzjLrg6adBFZ4quk27MdkRkdnAW4ArgQvF3VWfCngKazlwOVUWdS8OOKH22/f+lqNn7lcjCYCrVl7Fv9/z72SyGWINsWoOJxCymmXVllUcOv1Q2pJtgZ77iRee4Mo7ruT6x64nGUvyyeM/yceWfCyQcewc2MldG+7i9mdv5/b1t3PD4zcAMKNlBq+e82pec8hr+JtFf8PBUw+u+lgMIyh2736MtWs/A8Dg4PMhjyZaVFvULVPVTTnhdouIFH0LlROA1wAsWbKk+nEOtYAq9PTAaafBf/83rFkD3/oW/OAHcN11cPLJTty99a0Qi/4PtWGExdq1L10aRhF8A/gcMCX3fDqwU1WHc8+fBw7Kt7NfE5Wp4RQAc6bO4aD28U83q81Fd+xN72VK45Rxt4kSf1z3R9744zcSkxivOPAVvOaQ13DyISdz0pyT6GjqqMo5V21ZxRV3XMEvnvgFLYkWLnrVRVz0qouY2TazKucbj4PaD+KI7iM47xXnoao8s/MZbl9/O3957i/cvv52bnzqRr5855f56yf/ytSmqYGNyzCqRSaT4skn/5ZYrB0Q0umtYQ8pUlRV1Knqptxym4jcCBwPbBWRWTmXbhawrZpjiBTPPQdbtsAJJ7jnCxfC1VfD5z8P117rBN473gHz58M3vwlveUu44zWMiLJmzUuXhjERInIGsE1VHxCRU7zV42yadwLSr4nKVNqJuuZ4/jwTz0XaPbS7LkTdhhc3APDRJR9l1dZVXN1zNf92978hCEcfcPQ+kXdU91E0SGVFvTfv3szX7v4av/7rr5mSnMKlJ13KBa+6gBktM/x4K2UjIsyfNp/50+bzwWM/CMBdz93Fq3/4ar74ly/ytTd8LdTxGYYfrFt3MXv2PMZRR61g9epPMjRkoq4UqibqRKQVaFDV/tzjNwBfAH4DvB/4Sm7562qNIXL09LilJ+o8Ojrgoovg/PPhV7+CSy6BCy80UWcYZeI5dM89B0NDkEyGOx6j5lkGvE1E3gw04XLqvgF0iEg859bNBjZVeyCeU9ecKE7U1QN9A65A9pdf92WmNE4hlU7Rs7Fnn2t1zQPXcHXP1b6dr6Opg8tecxnnn3A+05qn+XZcv1k2ZxnnHHsOV/dczbnHncvhMw4Pe0iGUTY7dvyWjRu/xezZn2b69NN59tmZJupKpJpO3Uzgxlwybxz4iar+XkTuA34qIucAzwFnVXEM0WLlSmhqgpe/fPzX43F417tg1Sr48pdhcBAaG4Mdo2HUAZ5Dl83C+vXwspeFOhyjxlHVS4FLAXJO3WdU9X0i8jPgXbgKmIFMUpbq1NUDvale4g3xfe+rOdHMKXNP4ZS5pwAwlBnivo33sa5vXcXnSsaSnL7w9MiEM175uiv52RM/49O//zQr3rfCCqgYkWRwcDNPPfUBWluPZv78rwCQTM5k796nQx5ZtKiaqFPVdcB+WdyqugN4XbXOG2l6euC44wrbBosXQyYDq1fDkUcGMzbDqCPWroWjj3bzI2vXmqgzyuZi4HoRuQJ4CLi22iecjE5db6qXzubOvIIlGUuybM4yls1ZFvDIwqe7tZvLT7mcC/5wATc9fRNvPeytYQ/JMEpCNctTT32ATGYPixf/hIYGZ1YkkzN58cU7Qh5dtKgs+Nzwj6EhePBBOPHEwtsuWuSWTz5Z3TEZRh3S2wt9ffCGN7jnlldnlIKq3qaqZ+Qer1PV41V1oaqepaqD1T5/Kp1CEBpj+aM0WpOu+WK9iLq+gT46mzvDHkbN8olXfoJFMxZxwR8uYHC46h9Bw/CV55//Bn19N7NgwddpbV28b30i0U06vYNsdniCvY3RhNGnzhiPRx6BgYH98+nG47DDQASeeKL64zKMOsPLp1u61DUetwqYRpRIDadoijdNGGZXj07dtKbazW0Lm0QswdWnX80bfvwGrlp5FZecdEnYQ6p5du9excDAc2EPI3Di8Q5aW48kkaiN66m//yHWrbuE6dPP5MADP/KS15LJmYCSTr9AY6P1ay4GE3W1Qr4iKePR3Azz5pmoM4wy8ETcwoWwYIGJOiNapNKpCUMvoT5FndemwRif0xacxpmHnckVf7mCfzj6HzhwyoFhD6mmef75b7FlS9WjpWuWZPJAWluPorX1SNra3LKlZTGx2MTfLX6SyezhySffSyLRxWGH/dd+E1VO1MHQ0FYTdUVioq5WWLkSDjgAiu1ftHixhV8aRhl44Zbz5zthZ3MjRpRIDacmLJIC9Snqjug6Iuxh1Dxff+PXWfztxVz8x4u57h3XhT2cmuaQQ/4vBx30sbCHEThDQ9vYs+ex3N+jbNz4H4xEjTfQ3LyAeHxiF08kTnPzofvEYGvrUSSTs0ou0rNmzYXs3ftXjj76FpLJ/VuGJBJO1FmvuuIxUVcr9PQ4l67Yi2LxYrj5ZhgedlUxDcMoirVr4cADoaXFOXU33eTqDsViYY/MMAqTGi7eqduT3hPEkKpOX8py6oph/rT5XPSqi/jSnV/iY0s+xtKDl4Y9pJqluXkuMDfkUYTD9Olv2vc4mx1mYGAtu3c/yp49j7F37+NkMhNPBmWzA/T1/YGtW5fvWxePd+4TeK2tR9LcPI+Jynbs3fsEmzdfw8EHX8y0aePXThzt1BnFYWqgFtixw1Wy/NCHit9n0SJXXOWZZ+DQQ6s3NsOoM9ascQ4duOXQEGzcWLxJbhhhkkoXduoaY43EJFYXTt1wdpgXB1+0nLoiufTVl7J81XL+ccU/cu+H7624GbtR3zQ0xGlpOYyWlsNw3VmKZ2ho+0tcvz17HmPr1uvIZHYVtf+UKUuYN+8LeV83UVc6JupqgXvvdcti8uk8FucqBD3xhIk6wyiBtWvh9NPd4wULRtaZqDOiQDFOnYjQlmyrC1G3c2AngDl1RdKWbONfT/tX3vfL9/HDh37IOcedE/aQjDolmZxBMnkK06adsm+dqjI4uIHBwQ0F929rO46GhvwtvGKxKTQ0NJFOb/NjuJMCE3W1QE+PC7tcsqT4fQ4/3C2ffBLOPLM64zKMOmPPHti8eUTMjRZ1r31teOMyjGIpxqkD6kbU9aZ6ARN1pfC3R/4t37nvO1x666W8c/E76WjqCHtIxiRBRGhqmkNTU+WzpCJCIjHTnLoSMF++Fli50jURnzKl+H3a22H2bKvyYBglsG6dW3rhlwcfDImE9aozokMxTh3Uj6jrS/UBMK3Zwi+LRUT41pu+xfa92/nC7fnD2wyj1kkmTdSVgom6sFF14ZelhF56LFpkos4wSsBrX+A5dLGY6w5ibQ2MqFCsU9eabK0LUWdOXXkcO+tYzj3uXL5177d48gWrlG1EExN1pWGiLmxWr4a+PjjxxNL3XbwYnnoKsln/x2UYdYjnyHmiDpxrZ06dERUmm1Nnoq58rjz1SgRh+arlhTc2jBokmZxpLQ1KwERdsQwMuBJ5frNypVuW69Tt2QMbCiekGobhHLnOTpg2KpLLa0CuGt64DKNYLKfOKJau1i6mNk1l12Bx1QgNo9ZwOXUvoGrmRTGYqCuWf/kXOOooV//cT3p6oK3NCbRS8SpgWhNywyiKtWtf6tKBe97fD9u3hzMmwyiFYpqPQ/2Iur4Bl1NnxT7KoyXRQmo4FfYwDKMsXFuDDOn0jrCHEglM1BXLr37lwiRXrfL3uCtXwvHHl9f5eHRbA8MwCjK6R52H99xCMI0okEoXGX6ZaKuL5uO9qV7aG9uJN1ix7nJojjezN7037GEYRllYr7rSMFFXDGvXutw3gLvv9u+4qRQ88kh5oZcA06dDV5c5dYZRBEND8Oyz4zt1YMVSjNonq1kGM4OTyqnrTfVa6GUFtCRaTNQZkcUTdZZXVxwm6orh9793y7Y2f0Xdgw/C8HB5RVI8Fi82p84wiuDZZ11NobFO3bx5rk2kOXVGrTMwPABQUqEUjXiyqIm6ymhJtJBKW/ilEU0SCXPqSsFEXTGsWOGm8884w19RV0mRFA+vrUHEf7gNo9qMbWfg0djo+tWZU2fUOt7NebFO3XB2mKGMz3ngAdM30Me0JutRVy7NCQu/NKKLhV+Whom6QgwMwJ/+BG96EyxdCs8/D88958+xe3pg7lyYObP8YyxeDDt3wtYa/cBns7B8uft3NIwQ8Zy4sU6dt86cOqPW8QpeFOvUAZEPwTSnrjIs/NKIMvF4ByJJE3VFYqKuEHfc4XLfTj8dli1z6/xy63p6KnPpYKRqZq2GYN5+O3zgA87tNKqGiMRE5CERuSn3/Eci8oyIPJz7OybsMYbN2rXQ2jr+HIrX1sAwaplSnLrWZCtgom6yY9UvjSgjIiST3ZZTVyQm6gqxYoWLz3rta+HlL4eWFn9E3ebNzvGrVNTVelsDL8R0l/XJqTLnA2M/BJ9V1WNyfw+HMahaYu1amD/f5c+NZcECeOEF+5gatc1kc+pUlb5Un4m6CrDql0bUcb3qTNQVg4m6QqxYAa95jRNz8bgTYX6Iup4et6ykSArArFnQ3l67Tp33PndH98ai1hGR2cBbgP8Keyy1zHjtDDy89ebWGbVMqTl1EG1Rtye9h3Q2bTl1FWDhl0bUSSZN1BWLibqJWL8ennrK5dN5LF0KDz8Meyrs/7NyJSQScOyxlR1HxLl1tejUqY6Iukr/vYyJ+AbwOSA7Zv2VIvKIiFwlIo0hjKtmyGZh3br9i6R4WFsDIwpMNqeuN9ULYE5dBZioM6KOibriMVE3EV4rg9NPH1m3dClkMnDvvZUdu6cHjjkGmpoqOw7UbluD556DLVvcY3PqqoKInAFsU9UHxrx0KXA48EqgE7g4z/7nicj9InL/Cy+8UN3BhsjGjTA4mN+p80SdFUsxaplynLooNyA3UVc5LYkWBoYHyOrYOb/aRUTWi8ijuXzw+3PrOkXkFhFZnVuafTtJSCZnkk5vi3x7liAwUTcRK1a46pSHHTay7lWvcstKQjAzGbjvvsrz6TwWLXLVL3t7/TmeX3guHZioqx7LgLeJyHrgeuBUEfmxqm5WxyDwQ+D48XZW1WtUdYmqLunq6gpu1AGTr52Bx5Qp0N1tTp1R20w2p64v1QeYqKsEbwLA63EYIV6bywdfknt+CXCrqh4K3Jp7bkwCEomZqKYZHu4Leyg1j4m6fAwOwq23utDL0ZUVpk1zzlglou7xx104ol+irlaLpaxc6ZzIzk4Lv6wSqnqpqs5W1bnA2cCfVPXvRGQWgIgI8HbgsRCHGTqeWMvn1HmvmagzapnJllPnOXXTms2UKZeWRAtAPYRgngkszz1ejvtdMyYB1quueEzU5eOuu5wQGR166bF0Kdxzj0vUKQe/iqR41Gpbg54eeMUrnBA2py5o/p+IPAo8CswArgh5PKGyZo1LYT344PzbLFhg4ZdGfkSkSUTuFZFVIvK4iHw+tz6w9iGTzamz8MvK8USdNyEQERS4WUQeEJHzcutmqupmgNyyO7TRGYFioq54TNTlY8UKSCbh1FP3f23pUujrg7/+tbxjr1wJ06fnjwUrlUMOgebm2nLqhobgwQedG9naak5dAKjqbap6Ru7xqap6lKoeqap/p6rRvbPzgbVrXSR1LJZ/mwUL4PnnYSByUUpGQAwCp6rq0cAxwOki4s3MBdI+pKQ+dYno96kzUVc53gRAxJy6Zap6HPAm4BMicnKxO06WPPHJhCfqrFddYUzU5WPFCnj1q6Gtbf/Xli51y7vuKu/YXtPx8RpmlUNDAxx+eG05dY884u6OTzzR/RuaU2eEyETtDDwWLnQFW595JpgxGdEil6PqfZElcn+BZu6X4tTFGmI0xZsiLer6BvpIxpJFiVhjfKIYfqmqm3LLbcCNuJzwraPSCmYB2/LsOynyxCcTiYQ5dcViom48NmxweW+jWxmM5mUvc05bOXl1u3Y58eVXPp1HrbU18EJMzakzQkbVOXWFjHFra2AUQkRiIvIw7obyFlX1qkEF0j6kFKcOXAhmlEVdb6qXzuZOxK8J0EnIvvDL4WiEX4pIq4hM8R4Db8DlhP8GeH9us/cDvw5nhEbQJBKdQMxEXRGYqBuP8VoZjEbEuXXliLr77nN3mX6LukWLXAuB/n5/j1suK1fCAQe4JCZz6owQ2b7dzaUU49SB5dUZ+VHVjKoeA8wGjheRIwmwfUhqOEWiIUGsYYI44lHUi6gzysebAIiQUzcTuFNEVgH3Ar9V1d8DXwFOE5HVwGm558YkQKSBZLLbRF0RmKgbjxUrnBjxqkqOx9KlLqdu+/bSju05WMePW2G+fLyxPvWUv8ctl54eF3opYk6dESqF2hl4TJ8O7e3m1BmFUdWdwG3A6UG2D0mlU0WFXnqYqDOiFn6pqutU9ejc3xGqemVu/Q5VfZ2qHppb1lgPJ6OauF51JuoKYaJuLEND8Mc/7t/KYCxeXt3KlaUdf+VK1/dums8lmmuprcGOHbB69YgbaU6dESLFijoRt42JOmM8RKRLRDpyj5uB1wNPBdk+JDWcKim/rC3ZFunm430DfUxrsnYGlRDR6peG8RISCXPqisFE3VjuuceFMOYLvfRYsgTi8dJCMFVHHCy/WbDA1WyvhWIp997rlt77NKfOCJE1a5xgmzev8LYLF1r4pZGXWcCfReQR4D5cTt1NBNg+JDVsTp1RGhGtfmkYLyGZnGmirgjiYQ+g5lixwom1171u4u1aWuDYY0urgPnww7BtW3VEXTzuCrjUglPX0+Mqci5Z4p63tcHeva6vX4PNIxjBsnYtzJ4NTU2Ft12wAH71KxgedpeUYXio6iPAseOsH6fvTXVIpUt36rbtGbdIYCQwUVc5UQu/NIzx8ESdqlrhpAmwO+yxrFgBJ53kkmsKsXSpc6XS6eKO/cUvwtSp8J73VDbGfCxaVBtO3cqVcMQRI+0gWl2/JPbaj4oRPMnIze0AACAASURBVMW0M/BYuNBdzhs2VHdMpbJ5M9x2W9ijMMJmMjl16Uya3UO7TdRVSNSqXxrGeCQSM1EdJJPZFfZQahoTdaPZtMn1V8vXymAsy5a5XmwPF9Fr9qGH4MYb4YIL/M+n81i8GNatC7d7cjbrhO5oN9ITd5ZXZ4RAMe0MPGq1rcHVV7vggVoTm0awlOzUJaIr6voG+gAsp65CIlj90jD2w2tAbiGYE2OibjSFWhmM5VWvcsti8uouvxw6OuDTny5raEWxaJETVU8/Xb1zFGL1aujre2nLBk/UWV6dETD9/S7iuRSnDmpP1PX2ukv7mmvCHokRJqU6da3J1siKut6UK25oTl1lxBpiJGNJE3VGpDFRVxwm6kazYgUcdBAcdVRx28+eDXPmFBZ1DzwAv/kNXHihC7+sFl4FzDBDML2WDaOdOi/80pw6I2CKrXzpceCB0NhYe8VSvEvnP//TFeg1Jifl5NTtTe8lk81UcVTVwUSdf7QkWkzUGZHGRF1xmKjzGB6GW25xLl0pSZhLl7piKar5t7n8chdyef75FQ9zQl72MleIJMxiKT09MGUKHH74yDpz6oyQKFXUNTTA/Pm159T197vCLVu3wi9/GfZojLAoJ6cOohl615dy4Zcm6iqnJdFiLQ2MSJNIOFFnveomxkSdx8qV8OKLxefTeSxdChs35k92ufdeuOkm+Mxniiu+UglNTe6ONEynbuVKeOUrIRYbWWdOnRESnuNWrKiD2mxrsHu3i2iePx++852wR1M5GzbAWWe50FijeMpx6oBIhmB6Tt20Zsupq5TmeDN7h6Mn7A3DI5GYAYg5dQUwUeexYoUTIoVaGYzFa0KeLwTz8sth+nT41KcqGl7RLF4cnlO3d68rNDO2ZYM5dUZIrF0LXV2lzacsWODqDU1kvgdNf7+L3P7Yx+COO+DRR8MeUWX84Q/w85/DF74Q9kiiRTnNx4FINiC38Ev/sPBLI+o0NMRJJGaYqCuAiTqPFSucQOvoKG2/o492PevGE3UrV7rjfvazLiQxCBYtcoVShoeDOd9oHnzQnXd0kRQwp84IjbVriy+S4rFwoZt/2FpDvx27d7u5kQ9+0Bny3/1u2COqjNWr3fL733cC2iiOVDq1r0R9MUTdqROEqY1VzEOfJFj4pVEPWAPywpioA3j+eddyoNTQS3CJLiecML6ou+wymDEDPvGJysdYLIsXu0ZbYSQFeUVSxoq6WnHq+vrga19zZQSNScGaNaWFXsLI9rUUgrl7t5sXmj4dzj4brrsOdkW4Xc/q1XDAAZBIwD//c9ijiQaqWnZOXRRFXd9AH1ObphJriBXe2JiQ5kSzOXVG5EkkZlpOXQFM1O3ZA+96lyt59853lneMpUtdr7rRTtTdd8PNN8PnPjciaoJg0SK3DCOvbuVKmDsXZs586fpacep+8xvnmoZZSMYIjMFBl7tVrqirpWIp/f0jXyMf/7i7lK67LtwxVcKaNbBkiasd9ZOfFNfqc7KTzqbJanZS5dRZ6KU/WPilUQ+YU1eYyS3q0mmXrX/ffXD99a56ZDksXQqZjDuOx2WXQXe3uwMLEq/qZBiirqdnf5cOXHgqhO/UeaKytzfccRiB8MwzLi+u1PDLQw5x6bW14tSpjjh14OoQLVniCqbUUt5fsWSz7t/20EPh4otdYeB/+qewR1X7eOFzk8WpM1HnHy2JFlLDFn5pRBsn6qy61kRMXlGXzcKHPuRy3r7/fXj728s/llcYxAvBvOMO+OMf3R2L51IFxZQpcPDBwbtRmzY5W2RskRRwd8jNzeE7dd75+/rCHYcRCKW2M/BIJl37yVpx6lIp93U12vD/+MfdvM1f/hLeuMpl0yb3ng491KUwX3KJ+xq+/fawR1bbeDflpTh1rQn3+2OibnLTHLfwSyP6JJMzyWb3kMlEr/BTUExeUfe5z8GPfwxXXAHnnlvZsTo7XS6bJ+ouu8yFIH70o5WPsxwWLw7eqcuXT+fR1ha+qPOcQnPqJgWe01aqU+ftUytOnXfZjBZ1Z5/tHK5vfzucMVWCVyTl0EPd8lOfgoMOcuIuis5jUEw2p65voI9pTdbOwA8s/NKoB7xedRaCmZ/JKer+7d/g3//d3U34FfezdCnccw/cdhv8+c/uDqWl+CplvrJoETz1VLAFQXp6XNWDY48d//XW1vDDL03UTSrWrnXG9YwZpe+7YEHtOHWeqBtdQLe52QUa3Hijc76ixFix3dzsOr+sXAm//nVow6p5vJtyy6kzSsWqXxr1QDJpoq4Qk0/ULV/uXLr3vAe+8Q0Q8ee4S5e6sL5zz4VZs+AjH/HnuOWweLGLb3r22ZeuHxx0wvOqq9z7f/Wr/RM4K1fCMce4euvjUQtOneXUTSq8dgblXOILF7qPSS1E6vb3u+XYeksf/ajrIPJf/xX8mCph9WoX4nrwwSPrPvABOOwwN8eWyYQ2tJpmX/hlCU5dU7yJBmmInKjLatZEnY944ZdqVrgRYUzUFWZyibqbboJzzoHXv96JuwYf377XhHztWrj0Ujf9HBaLF7vlH/8IN9wAF1zgct3a2904L7zQvXbnnbBqVeXny2Tg/vvzh16COXVG4JTTzsCjlipgjufUgROeb3yjSwlOp4MfV7msXu3+fWOjKtXH43DllS4V+L//O7yx1TL7wi9LcOpEhLZkG3uGopWD0j/YT1azJup8oiXRQkYzpLMR+qIwjDF4os7aGuRn8oi6u++Gd7/bhQf+8peuhYGfvOxlronUQQfBhz/s77FLxWtrcN55Lvnm+993U+Pnnw+/+AVs3OjCRAFeeKHy8z3+uBNM4xVJ8agFp85E3aQhk3HVL+tB1OVz6sAVTNm0yXXriAqrV4/k043mb/7GVfa87DIYGAh+XLVOOU4duBDMqDl1fQPOIrecOn/wGtZbXp0RZRKJbsCcuomIV/sEIhID7gc2quoZIjIPuB7oBB4E/l5Vh8o+QSZTOLv+qafgjDNg9mz47W/3n/L2AxG49lon7PKFIAZFZyd873suNuvEE+HlL3f5bqPxpsn9EHUrV7plIadu+/bKz1UJFn45adiwwblX5RRJAZg/3y1roVjKeIVSPN7yFlep8zvfKb/NZpBks04on376/q+JwFe+Aq97nXs/F14Y/PhqmXKcOsiJunS0RF1vyn1Hm1PnD56oS6VTdDR1hDwawyiPhoYE8XiniboJCMKpOx8YXV//q8BVqnoo0AecU9HR/+7vnGCZ6O+oo5wz94c/uN5x1eLMM+Gkk6p3/FL4yEfgE5+AV7xif0EHTnyCP6Kup8cdbyJbxJw6I0DKbWfg0drqUmNryakbby4qFnO5dX/6U/BdTMph40bnwuUT26eeCm94A3zpS/Dii8GOrdYJ2qkbygxx7m/OZf3O9SXvWykm6vzF+8yYU2dEHWtAPjFVdepEZDbwFuBK4EIREeBU4L25TZYDlwPfLfsk7343HHHExNs0NLjt5s0r+zR1RzzuHD2/nLoTTpi4IoXl1BkB4omxcp06b99aEHUTOXXg0oQvuwy++1345jeDG1c5jG1nMB5f/rKbi/ra1+CLXwxmXFGgIqeuDFH39I6nufahaznhoBP48CuCTSnoS7nwSxN1/mDhl0a9kEzOtJy6Cah2+OU3gM8B3hzzdGCnqg7nnj8PHFTRGd7xDvdnlE5XF2zbVtkxdu1yFsF73jPxdubUGQGyZo0z5w+q4NtlwQK4+Wb/xlQu+QqleHR3w1lnudpPX/pSfvFXCxQj6o47zn2dfP3r8MlPupafRvlOXWuilRf2lj5557llXn5bkHjnntZsOXV+sC/8ctjaGhjRJpGYye7dD4Y9jJqlaqJORM4AtqnqAyJyird6nE3HTYgTkfOA8wDmzJlTlTFOerq6Knfq7rvP5TROVCQFRpw6Vf/aSJSKd3f84osuF3N0+b2IU+3c1TVrXE+0qHDLLS4vrpICtwsXwo9+BF/96sTH6e52eWCzZ5d/rono73fGejKZf5uPfxx+8hP3d9551RmHH6xe7cR2oX+rK65wNZ0+9CE45ZSJtz3qqPFz9OqNSpy6Z3Y+U/L5PLds58DOkvetlH2izgql+IL3mTGnzog6Fn45MdV06pYBbxORNwNNQDvOuesQkXjOrZsNjNs6V1WvAa4BWLJkiTVXqQZdXfDXv1Z2DK9IyvHHT7xdW5sTdKlUeE3Z9+xx+YXpNOzcOZJXWB94uavtuede7ur1IvI9XO5q2WHOTzzh2jtGiXPPrWz/E090Yu6SS4rb/rDD4LTTXMeUU06BqVMrO7/H7t3u8ploLmTpUhddfvPNtS3qvDYThcT2woXu8/alL8HvfjfxtuecM0lEXcA5dZ6wCkvUNcebS36vxvhY+KVRLySTM8lkdpHJDBCLhVyUsAapmqhT1UuBSwFyTt1nVPV9IvIz4F04F+H9wK+rNQajAN3drlddJfT0wOGHQ0eBilqtrW65Z084ok7VnXvuXFfrvre3bkRdELmrb35z+NGzpVLpx+x1r3MfmULNsNeudW0fb7kFfvAD+I//cCbw8cePiLxly8p3Dfv7CxfsFXGXs1dUpVbJ185gPK68Ev7P/ylc3Dhe9RrOtUEqnaJBGkg0jFP4agLKFXVe2GUYoq5voM9CL31kdPVLw4gyo3vVxWKHhDya2iOMn8OLgetF5ArgIeDaEMZggHPqduxwdcbLveN86KHC8VEwkuize7c7b9CkUu7u8OCDR0Rd/VD13NV4fPLcPI+mmO4kL3+5+7vwQhgchHvuGRF5V1wBX/iCc5wuvbS8MXhOXSFqIW11Irx2Bm9+c/H7hGXq1yKp4RTN8WakxPD1cpuPh+3UWZEU/7Dql0a9kEg4UTc0tJWmJhN1Ywmk+biq3qaqZ+Qer1PV41V1oaqepaqDQYzBGIeuLnenVa7AyWZhyxYnlAox2qkLA++83ljrRNSNzl0dvXqcTfPmrorI/SJy/wt+VEKd5DQ2ujmOK65wJvb27c4QXr++/GPu3l1ca81aF3UbNjjRW6xTV2uISJOI3Csiq0TkcRH5fG79PBHpEZHVInKDiEyQ/Vg+qXSqrHDEtmQb6WyaoUxpKbVh59SZqPMPC7806gXPqbO8uvEJRNQZNYrnmJVbAbO31zU4P+CAwtuOdurCoE5FHSO5q+txIc2nMip3NbfNhLmrqrpEVZd0heGg1jnTprnOIbt2lX+M/v76cOq8Ru6VtJkImUHgVFU9GjgGOF1ETsTv3qt58Jy6UmlLug9PqSGYvQPm1NULVv3SqBdM1E2MibrJjHcTX65DszV3URVTc9y7Kw3bqfMqqdaJqFPVS1V1tqrOBc4G/qSq7wP+jMtdBctdDZX29spEXb04dcW0M6hl1OH9Cydyf4qbSPl5bv1y4O3VOH9quHynDkoXdWE6dX0DfVb50kes+qVRLyQS3QDWqy4PJuomM0GKOi/8Mqy7Tu+8Xi31OhF1E3AxrmjKGlyOneWuhkR7u+uiUS7FOnVTpgRzeT32GDzwQOHtxrJ6tctRrKR3YNiISExEHga2AbcAa/G792oeUulgnbowC6WYU+cvyViSBmkwUWdEnlisiVhsqjl1eZiEpQ+MfXS7GY9J5dS1t7ta83Uo6lT1NuC23ON1QIE+E0YQTJ3qCoSUSymFUvburX4LxvPPd/lxTz9d2n6rV7vQy0p6B4aNqmaAY0SkA7gRWDTeZuPtW2nv1XKdutaEm1ArOfwyVyglNZxicHiQxnhjyecuh4HhAfam95qo8xERoSXRYtUvjbogmew2UZeHCP+8GhUzY4Zblivqtmxxy2Jy6sJ26jxR19rqkpzqUNQZtUml4ZfFtDSAEeG3t8qT8evXO4G2tcTf1DVroht6ORZV3YmbQDmRgPJXA3fqUn3ExM0OBOnWeWGfJur8pTnebE6dURdYA/L8mKibzCQSrr9cJU5dMlm4Rx2E79R5YrKtzYm6vr5wxmFMOioRdZmM68ZRrFMH1Z03yWadSwdw113F75fJOLcywkVSEJGunEOHiDQDrweeJKD81SBz6rKapW+gjzlTnaMYqKjLhX1aTp2/tCRa2Dtsos6IPonETMupy4OJuslOV1dloq6723U+LoQ5dcYkxRN1hZpoj4f3sS3FqatmA/KtWyGddo/vvLP4/TZsgKGhyDt1s4A/i8gjwH3ALap6EwHlrwbp1PUP9pPVLPOnzQeCFXVe2Kc5df7Skmgxp86oC8ypy4/l1E12urrKb2mwdWtx+XTgOlc3NoafU9fa6urMP/dcOOMwJh1Tpzqnau/ekbmNYvEEWq04dd5lE4+XJuqiXvkSQFUfAY4dZ30g+auVOnWlNCD3hNW8jnmAibp6wHLqjHohmZzJ8HAf2ewQDQ1VaQsaWcypm+xU4tRt2VJcPp1Ha2v41S+98Etz6oyAaG93y3JCMEd/bAsRpKg7/XR46KHi52i8HnVRFnVhE6RT54VAzptmoq5eaE5YTp1RH4z0qivTkKhjTNRNdioNvyzWqYNwG2nt2ePshWRyRNSVEw9nGCVSiajznLpSwi+DEHXvfS8MD8O99xa33+rV0NwMs2ZVb2z1TrnNx1uTpVe/9IqVhBF+6Z17WrPl1PmJhV8a9UIi4e47La9uf0zUTXa6u2H7dlcBoRSyWRe2WYqoa20NN/zSi33r7HTxcNVMPjKMHFOnumU5vepq0ambMgXe9CaXSltsCGY9tDMIm1S6vPDLeEOcpnhTSaLOc8vCyqlrkAbaG9sDO+dkoCXRQmo4OuGXuZ6QD4nITbnn80SkR0RWi8gNImJxd5OUEafORN1YLKdustPV5QTOzp1O7BRLb6+bqi8l/DJsp8676/XeZ2/viI1iGFXCj/DLYpw6b5tqi7o5c1zB2yOPLE3UHXFE9cZV72SyGdLZdFlOHbgQzHLCLw+cciDJWDJwUTetaRoNYjMAfhLBlgbn46rLej/SXwWuUtXrReR7wDnAd8ManBEeQYu6dHonzz33ZbLZYCZFZs36MG1tR5W1r4m6yY7XL+mFF0oTdaU0HvcI06nbvfulTh04UTd3bjjjMSYNfoRf1opTt2GDE3UAJ50EP/5x4WbnmQysWwdvf3v1xlXveA5LOU4duAbku9OlO3WdzZ10NHUE3tLA8un8J0rhlyIyG3gLcCWusqwApwLvzW2yHLgcE3WTkqBFXV/fLWzY8K/EYu2ITPBj5xOdnW8yUWeUiSfqtm2Dww4rfr9yRF1bG2zcWPz2fjI2/BKsWIoRCJ6oqyT8spZy6pYscY9POgm++1149FE45piJ90mno92jLmy8qoWBOXWpPhpjjTTHm52oGwzYqbN8Ot+JWPXLbwCfA7xvvunATlUdzj1/HjgojIEZ4ROLtdLQ0BpYTl0m42ZkX/nKR2lqmhPIOcvF4hsmO6OdulKImlNnos4ICS+nrtpOXTIJiUT1RF0q5b4mDj7YPV+2zC0LhWDWQzuDsKnUqStV1HnCSkToaOrYV7wkCHpTvebUVYGohF+KyBnANlV9YPTqcTYdt9KZiJwnIveLyP0vlFsEzqh5guxVNzzsfohjsSJmV0PGRN1kp1xRt2WLW0Ylp2737v1z6vqCu1ExJi+ey1ZJTl2x/e2qeYlt2OCWXvjlnDkwe7aJuiAI3KkbFQIZdPilibrq0JJoYTAzSCabCXsohVgGvE1E1gPX48IuvwF0iIgXXTYb2DTezqp6jaouUdUlXd79jVF3BCnqMhkTdUZUqMSpSyZdxYRiqRWnbloutMecOiMAEglXzr9cp6652XXjKIa2tuoVdfXaGXiiTsSFYN5558TdQVavdpeetTMoHz+culKbj09rct+TYeTUeec2/KMl0QLAwPBAyCOZGFW9VFVnq+pc4GzgT6r6PuDPwLtym70f+HVIQzRqgGBF3S4aGppoaKj9jDUTdZOdxkaX9FOOqOvudnd2xeLZCGH0hxst6pqa3J2yiTojINrby8+pKyb00qOaTt1YUQdO1G3cOPLaeKxZ4/LpSvmqMF5KGE6dl9fW0RicqMtqlr6UFUqpBt6EQBRCMPNwMa5oyhpcjt21IY/HCJFEYmZgOXXDw/3EYtGolG6iziivAfmWLaXl04ETVZkMDA2Vtp8fjL079hqQG0YATJ1afvhlMUVSPKot6kTgoFHlCYrJq/N61BnlE3RO3WhhFaRT9+LAiyhqoq4KeE5dlESdqt6mqmfkHq9T1eNVdaGqnqWqg2GPzwiPZHIm6fQOstnhwhtXSCbTH4nQSzBRZ0B5om7r1tLy6SCY8nz5GO3UgYk6I1Da28sPv6wlp27WLBd17XHUUU505hN1w8OunYHl01VG0E7d2PDLwcxgIGF7o1spGP7iibooNSA3jHy4tgZKOl39YjiZTD/xuIk6Iyp0dbmWBqWwdWt5Th0En1eXycDAgIk6IzTKFXW1FH45ukedRywGS5fmF3XPPuuEnYm6yvAlpy69h6xmC26bzqTpH+p/iVMHBOLWeU3PLafOf7wJgSg5dYaRjyB71Q0P7zKnzogQpTp12awTgaWKurCcur25HzETdUZIlJtT199fWvjllCnVderGijpweXWPPz5+Mdk1a9zSRF1lVOrUtSbcd18xN/SeePOElZdbF4SoM6euekQx/NIw8pFIuPvPIPLqXPil5dQZUaG7G7ZvL76ASW+vm34vNfwyLKfOu8u1nDojJCrJqasFp07ViTqvR91oli1zr99zz/6vee0MLKeuMvxw6oCiQjA9tywMp85EXfUwUWfUE0E6dRZ+aUSLri5Ip4u3EsppPA7hOXWeiDSnzgiJSsIva6FQyvbtLoJ5PKfu+ONdy4XxQjBXr3ZjKnX+x3gpfuTUQXGizhNW+6pfmqirC/bl1KUtp86IPiOirsTUoTKwQilGtCi1V125oi4spy6fqBsYgJT9wBnVxxN1pXbzKKdQyp49LkLaT8ZrZ+DR2grHHZdf1Fk7g8oJ1KlLje/UeeuriXcOT1Aa/lEHLQ0MYx+x2BQaGpoCCb+0nDojWgQl6sJy6vKFX8L4iUCG4TNTpzqhVep8RjlOnepIGqlfTCTqwOXV3XcfDI4pMr5mjeXT+YHnrjTFm8ra3xN1xTQg3+fUNYXj1LUmWknGkoU3NkrCwi+NekJESCSq34BcNUM2u5d43HLqjKhQqqjbssUty21pUCtOHVgIphEI7bnfg1JCMAcHXVR0qU4d+D9vUoyoGxiABx8cWTc8DM88Y/l0fpAaTtEYa6RByvvJLienLpTwy4FeC72sEtbSwKg3ksnqi7pMxn1nmlNnRAdP1BXb1mDrVtesqqOjtPN4oqoWcuqm5cJ7TNQZAVCOqBvPYC5ENUVdczNMnz7+60uXuuXoEMz1662dgV+k0qmyQy+hvPBLz6lrijfRGGsMpqXBqKbnhr9YSwOj3ghC1A0P9wMm6owoUU74ZXd36YkyYTl1E4VfmqgzAsATdaW0NfA+tqWGX47e1y+8HnX5LvmZM514Gy3qvMqXJuoqJzWcKrtICpReKKUt2UYilti3rqOpI7DwS8unqw6WU2fUG8nkzKrn1GUybibWRJ0RHZqb3d1gKeGXpebTgXP34vHacOpM1BkBMnWqW5bi1PW7CcKaceryhV56nHQS3HXXSDEY61HnH6nhAJ26gf3dso6mDnYOBiPqzKmrDg3SQFO8yapfGnWDy6l7AVWfK4ONIpNxP8SWU2dEi1IakG/dWn6Ncq88X5CYqDNCppLwy1Kbj4/e1y/y9agbzUknwY4d8Ne/uuerV7vxdHf7O5bJSCpdmVPXmnTffcU6dV7opUeQTl1nk4m6atEcbzanzqgbksluIEM6Xb37OAu/NKJJqaKuHKcOnLCqBaeurc25hibqjAAoR9TVilM3OAibNxd26pYtc0svBNPaGfhHaji1r9BFOTTHmxGkbKduWvO0YHLqBvos/LKKtCRaTNQZdUM87r6nhoerdx/nOXUm6oxoUayoy2ZdQZVyRV21uiNPxO7d0NQEsdjIOpG6aEAuIk0icq+IrBKRx0Xk87n1PxKRZ0Tk4dzfMWGPdTJTSU5d2KJu40a3LCTqXvYymDHjpaKunkIvReRgEfmziDyZu9bOz62/XEQ2jrrW3uz3uSstlCIitCXbinfqmoN36lLpFAPDAxZ+WUVaEi1W/dKoGxIJT9RVrzWVl1MXj0dD1MXDHoBRI3R1wcMPF96ut9eVtCs3/LK1NZzwy9EunUcdiDpgEDhVVXeLSAK4U0RW5F77rKr+PMSxGTkqcerCLpRSqJ2Bh8hIXl067apfnn22f+OoAYaBi1T1QRGZAjwgIrfkXrtKVb9WrROnhlP7hUSWSrGiri/Vt18IZEdj9UWd1x/PRF31aE5Y+KVRP3hOXTDhl5ZTZ0QJz6nzqhzko9zG4x5hOHV1LOrU4f2DJnJ/Bf4TjaCJx6GlJZotDYoVdeBE3Zo10NMDmUx9OXWqullVH8w97geeBA4K4tyVOnXgRN2edOEJtfFCIDuaOuhL9aGFfh8qwERd9bHwS6OeSCTc95SFX45gos5wdHfD0NCIPZCPSkVdGE7d7t3j3xl3dkJf9Wz7oBCRmIg8DGwDblHVntxLV4rIIyJylYg05tn3PBG5X0Tuf6HYnEqjLNrbq9/SoLHRRRkXuoxLwRN1s2cX3tbLq/vhD92yXhuPi8hc4FjAu9Y+mbvWfiAivieFVdrSAIpz6rwQyPEKpaSz6aqG7u1rel6hI2nkx0SdUU8E4dRlMv2IxGloGPcWquYwUWc4iu1Vt2WLW5pTVzOoakZVjwFmA8eLyJHApcDhwCuBTuDiPPteo6pLVHVJl/cZMKrC1Kmlh182NLiOI8Ui4v8ltmGDm/MpZhzHHefSV3/6U/e8npw6DxFpA34BfFpVdwHfBRYAxwCbgX/Ps1/ZEyiVVr+E4kSdJ6zGa2kAVDUE05y66tMcb7acOqNuiMc9p66aOXX9xGJTkIhU/DJRZziK01jMfAAAIABJREFUFXWeU2c5dTWHqu4EbgNOz4WKqaoOAj8Ejg91cAbt7aWHX7a1lV490m9RV0yPOo9kEk44wZ2/vX3ka6VeyOWt/gL4f6r6SwBV3ZqbWMkC/0mea62SCZRK+9RBcaLOE1bjhV+CibqoY06dUU80NMSJxdqrnFO3KzL5dGCizvAoRdQlk9DRUd55asmpmzbN3WWn08GOx0dEpEtEOnKPm4HXA0+JyKzcOgHeDjwW3igNKF3U9feXlk/nEaaoA5dXB86li8jkZlHkrqVrgSdV9euj1s8atdk7qMK1FphTlzKnrp4xUWfUG/H4tKrn1EWl8iVY9UvDoxRR191d/t1areXUAezcGWVLYRawXERiuEman6rqTSLyJxHpAgR4GPhomIM0nKjzopeLId/HthBTpvgn6lSdqDvttOL38fLq6jCfbhnw98CjuRxWgH8C/jbXMkSB9cBH/Dypqvri1LUmW4t36sbJqYPqirq+VB8xidGWLONDbxRFS6KFVNrCL436IZHoDCT8MiqYqDMcnqjZtm3i7bZsKT+fDtxd6tCQc8cSifKPUwoThV+CC8GMqKhT1UdwBRvGrj81hOEYE1BqTt3u3aUVSfHw06nbudMdqxSn7lWvcmb+kUf6M4ZaQVXvxE2SjOV31TzvYGYQoHKnLlH7OXWdzZ2RyV2JIs1xa2lg1BfxeGfVWxrE41Ordny/MVFnOFpbXc31Ypy6Aw+s7DzghFa5IZylUoyoM4wqE2T45aZNpe83HqW0M/Do6ID774d58/wZw2THc1bCzKnznldV1A30WuhllfHCL1XVxLNRFyQS09izZ2PVjp/J7KKxsYjSzzWC5dQZI3i96iZi69bKnToINq+uUPiliTojADxRV2yrr1pw6soRdQBHHVWeIDX2x6tW6EdOXTqbZigzlHebvlQfDdJAe+NLCwNMbXQz1UE4dUb1aEm0oOiEnwHDiBLVdupcTp0VSjGiSCFRl8268MxKRN1opy4IhoZgeNicOiN02tudoCtWcNVCoZRyRZ3hH164nB9OHcCeofzfvX0DfXQ0ddAgL701aIw30hxvrnpO3ViH0PAX7zNkIZhGveDl1Gmxs6UlMjwcrZw6E3XGCIVEXW+vE0jltjOA4J06TzyaqDNCZmouLL/YEMxyC6W0tfnXfPy551x+XHe3P8czSmdf+KUPTh0wYQhmb6o3b/PvjqaOfdUxq4E5ddWnJdECmKgz6od4vBPVNJmM/0aBqkauUIqJOmOEQqLO61EXJafOE4/j3R1PneqqePZV70bFMDzacxEcxYq6/v7Kwi/9mLjcsAEOPtg1QTfCYV/4pU9O3USirm+gL6+w6mjqYOdglcMvm0zUVRNP1FkDcqNeGGlA7v/kfDa7F8hGqqWB/VQbI3iiLt/doB+irpaculjMVXUwp84IAE/Uvfhi4W2zWffRLdepU4WUD/dtpfaoM/wncKcuTwhkR1NH1cIvM9kMLw6+aOGXVcb7DJlTZ9QLiYSbCKpGW4PhYRfyYs3HjWjS3e3uBPO5aF6TrSg5dROJOnAhmCbqjAAoJfwylXLCrFynDvyZN3nuOefUGeERqFOXKuDUVUnUece18MvqYuGXRr0Rj7vvjGoUS8lkPFFnTp0RRQo1IPecunrJqQOYNs1EnREIpYRfejlx5TYfh8ovseFh2LjRnLqw8cupa02678BKcuqqJeq8Vgom6qrLvvBLa0Bu1AkjTl31RJ2FXxrRpBhRl0xW1l+ulnLqwJw6IzBKEXWFPrYT4de8yaZNLgzURF24BOXUqSo7B3aG4tSZqAsGq35p1BteTl01nLrhYfdjbU6dEU2KEXXd3a64SLnUmlNnos4IiFJy6jynLszwS2tnUBsElVPXP9RPRjMFnbpqlA7vG3D5MPnObfiDhV8a9UY1c+pGwi8tpw4RaRKRe0VklYg8LiKfz62fJyI9IrJaRG4QkWS1xmCUSCFRt2VLZaGXAE1NThRaTp0xyYiaU2eirjYIyqnz3LJ8xUqmNU1jODtcFUFgTl0wmKgz6o2GhhZEklXNqbPwS8cgcKqqHg0cA5wuIicCXwWuUtVDgT7gnCqOwSiFYpy6SoqkgBN0fnZHLkQx4Zd9fS7OzDCqSCzm5hZKEXW14NRZoZRw8S2nLuEmtvakx59Q83rQTRR+CVQlBNNEXTB4nyFraWDUCyJCPD6tqjl1Fn4JqMO7rUjk/hQ4Ffh5bv1y4O3VGoNRIm1tzknbtm381/0Qdd55asmpy2aLbx5mGBXQ3l79QinePpU2IN+wwV0e5YzB8A+/nLpELEFjrLGwUzdB+CVUV9RZS4PqYk6dUY8kEp1VamlQ5zl1InKiiPxJRO4SkYJiTERiIvIwsA24BVgL7FTV4dwmzwMHlTpoo0qI5G9Ans36J+paW4PNqROB5jw3RJ25mWELwTQCoL29uJy6WnHqLPQyfFLpFPGGOPGGeMXHaku25RV1Xl5bIafO285P+lJ9TElO8eU9GvkxUWfUI/F4ZxXDL4VYLI8pUINMKOpEZGwC1YXA24DTgS8WOriqZlT1GGA2cDywaLzN8pz7PBG5X0TufyFfOKDhP/lEXW8vZDKV59RB8OGXLS35i7t4oq6vhBuVT30Kfve7ysdmTDqmTg3OqTNRVx+khlMVh156TCTqCrllVXXqBnot9DIAErEE8Ya4tTQw6grn1FVH1MVibYhEp6ZkoZF+T0T+WUSacs93Au8F3gMUHa+mqjuB24ATgQ4R8abjZgOb8uxzjaouUdUlXV6ul1F98ok6r0edX05dkOGXE90Zl+rU7doF//EfcP31lY/NmHQUG35ZSaGU5mY3h+GHqLN8uvBJpVMVh156TOjUhZxTZ6IuGJrjzebUGXVFPD6tSi0N+iMVegkFRJ2qvh14GLhJRP4e+DSQBVookAsnIl0i0pF73Ay8HngS+DPwrtxm7wd+XckbMHwmCFEXpFO3Z0/+fDooXdQ9/rhbPvNMZeMyJiXFhl/297uWkMkyagP7UYto1y7YudOculrAT6euNdk6oVOXjCXznstEXX3QkmgxUWfUFdXKqctkdtWXqANQ1f8F3gh0AL8E/qqq31TVQjGRs4A/i8gjwH3ALap6E3AxcKGIrAGmA9dW8gYMn8kn6rZsccsoOnUTibppuVAjE3VGAJTi1FVSoGTKlMpE3YYNbmmiLnxSwwE5dQN9dDZ3InlC1ac2TQWqI+r6Un1WJCUgWhItNV390tphGaUSj3eSyfSTzaZ9PW4m0088Hp0edVA4p+5tInIn8CfgMeBs4B0i8j8ismCifVX1EVU9VlVfrqpHquoXcuvXqerxqrpQVc9S1UG/3ozhA11dTgjtHTOT5zl1Ucypm+juuFxRt2kTDAxUNjZj0lFsTt3u3eUVSfGo9BKzHnW1QyodTE5d30DfhM2/k7EkLYmW6jl1TebUBUFzoubDL60dllES8bj73vLbrau78EvgCpxL907gq6q6U1UvBP4FuLLagzNCoLvbLce6dVu3uliwjo7Kz1FLTl1jo3u9VFGnCs8+W/n4jElFe7sLrSzUFrG/vzKnzkRd/RCUU9eb6i3olnU0dfgu6lTVwi8DpNbDL60dllEqiYT77vBb1LlCKfUl6l7EuXNn49oSAKCqq1X17GoOzAiJfA3It251gi9fFclSqKWcOnB5daWIuvnz3WMLwTRKpL3dzQcU+vhXGn5Z6SW2YYNrlj5rVvnHMPzBV6cu0TZh8/FCwmpa0zTfRd1DWx4inU2zoHPC4B/DJ2o9/BIqa4dlldMnH/G4+97yu1hKJrOLeLy+RN07cEVRhnFVL416J5+o27LFn9BLcCJrYMC1SKg2xdwdFyvqdu50YZdvfat7bqLOKJGpLi2pYAhmf3/44ZezZzthZ4RLoE7dBOGXUB2n7kcP/4hkLMk7F73T1+Ma4xOF6peVtMOyyumTjxGnzl9R58Iv6yinTlW3q+q3VPV7qlp0CwMjwkzk1PlRJAVGRFYQIZh+OnVe6OXrX+/CNk3UGSXSnvt9KCTq/HDqvF535WA96moHv3Pq9gztIav7x/96hVImwm9RN5QZ4ieP/oQzDzvTCqUERK2HX46mnHZYxuTDy6nz36mrv/BLY7IRhKjzRFZURd1RR8HcubBuXcXDMyYXpYi6sJ0661FXG/jt1Cm6X/Pp4ewwuwZ3FeXU9Q34l7fyu9W/Y0dqB+8/+v2+HdOYmFoXddYOyyiVauTUZbODqA5FLvwyXngTY1LR3g6JxEtFXTZbHaeu2nl1qsWLur4ivgwef9yNfc4cmDfPnDqjZDxRV6hXXZiFUjIZeP55c+pqBb+dOoDdQ7tpTY58L3ruW9BO3fJVy5nZOpM3Lnyjb8c0JqY53ryfqK8xZgHLRSSGMx5+qqo3icgTwPUicgXwENYOy8gRj7sCfn46dcPDLtQlak6diTrjpYi4giijRV1vr7vT8zOnDqrv1KVSTtgVm1OnOnEhmMcfh8WL3Tbz5kFPj7/jNeqeYnPq/HLqCn2kx2PrVkinTdSNRUQOBv4bOADIAteo6tUi0gncAMwF1gPvVlXfpoz9bj4OTtTNZGSSrjflboaKrX6pqnn72RXL9r3b+e3Tv+VTx3+KeIPdigRFrTt1qvoIcOw469fh8usM4yWIxIjFpvqaU5fJeKKujnLqjElKVxds2zby3OtRFzWnzhONxTh1g4NOBE7EY4/BEUe4x/PmOXdvp/89m4z6pZjwy+FhV0eo0ubjmYz7WJeKtTPIyzBwkaouwuX4fEJEFgOXALfm+mfdmnvuG6m0v+GXwH7FUvpSToMW49RlNZu32Eop/M+j/0M6m+b9x1joZZDUuqgzjHJIJDp9Db/0RF3Uwi9N1Bn709X1UqfOb1EXlFNXrKgrpgH5jh3u38ETdTXS1kBEmkTkXhFZJfL/27vb4LiqM0/g/6f7dlvderNkW8IhJpgsMTAEm6xJJfYUk5CQEDJVkKoMO8w6660lxXwIM8luajZUvky2dqqG3dokNTW7laqkoNBMSLLMkBcqyyTjciXLZAgsDiMbY5I4AQMGW5Jt2W7JLalfzn44faxWq1/u7b5v5/b/V+VqqdXqPog+Uj/9f8458pKI/Jfa9dtF5DkROS4i/1tEspEOlAC4a78073X02n5Zf19esKhrTil1Sin1Qu3jAvQ6nysB3AV9bhbg8/lZpUoJFVUJpP2ynlkn52ZNHQBfWjCnDk9h1xW7cNPkTT3fF7mXz+RRqpZQrpY735jIEo4z7mv75WpSx6KObNdY1J0+rS9tS+rcvjoer7073a6oM5uk1Cd1QORFHYBlALcppXYC2AXgDhF5H4D/BuCrtfRgHsB9EY6RakxLZbukzuxa2Wv7JdDdFHvjDX3Joq41EbkaukXsOQCTSqlTgC78AEz49TjmPLGgkzov7ZdA70Xd0dmj+MWpX3CDlAiY51LM19UReaKTOj/X1Ok/0izqyH6tkjrb1tR5ab8ErCzqlGZeoWVq/xSA2wD8fe16X9MD6l46rQuudkVdHJK6kZHV9X+0logMAXgCwOe8HPXTzaHI5oW330ld4wHkXtovgd6LuqnpKTgpB3/0bh5/G7Z8Jg8AbMGkRHGcsUCSOsfhmjqy3ZYtOi4wC3JmZoBsFti40Z/7j+OaOqBzUTcyok9kBnTL5uho5EUdAIhIWkSmAcwCOADgtwDOK6VMf81J6DYxioGREXdFXVRJHc+oa01EMtAF3WNKqe/Wrp4Rka21r2+FnofrdHMocuhJXYf2S/P1Xoq6crWMb774Tdx57Z2YGPQt1CSXTFFnnltESRDUmjomdWS/idofWvNu8unT+roedzu7LKykzu/2S7PzpXHNNbE4q04pVVFK7YI+kPW9AK5vdrNm39tNekC9GRlpv6bOtF/6kdR1cwA5z6hrTvR2jw8DeFkp9ZW6Lz0JfW4W4PP5WUEldc3W1A1lh5BJZ9p+vx9J3YHfHsDphdNsvYyIeS4xqaMkMWvqlGr6UsczW480YFFH65l3kc0OmDMz/rVeAkBev1NoXVJnWi+NmJ1Vp5Q6D+Cn0DvzbRQRs0/42wG81eJ7PKcH1JvR0fi3XzKpa2ovgE8BuE1Epmv/7gTwEIDbReQ4gNtrn/sizKSuU0oH+FPUTR2ewnhuHB+/9uNd3wd1j+2XlESOMwagcjlh65WtSR0Ph6H1zIt7k9zMzABve5t/959K6cIuLmvq8nndXtqqqJub0/+aFXVPPdXdYWA+EZEtAEpKqfMikgPwYehNUn4C4JMAvgOf0wPqTaf2yyg3Srl0CThzhkVdM0qpnwFoNdE/FMRj+p3U5ZwcBNI0qeu0ng4ARgdGL9++G+eXzuP7v/w+Pv2eT2ODs6Gr+6DeXG6/5EYplCCZjP79VS7P+7IOrlK5iFQqh5RlZ2gyqaP1mhV1fu18aZjTkYNk7r9TUSeyegB5M42bpBjbt+sDxczuoNHYCuAnInIEwPMADiilfgjgCwD+k4j8BsAm6LYxigG3a+qiSOq482W8+J3UiQgGs4NNz6nrtPMlADgpB0PZoa6TusdfehzLlWW2XkbIPJeY1FGSOI4u6vzaLKVcLliX0gFM6qiZ+qKuWg2mqBscDC+pc/PqeHxcHybeTKuizpxV98orwNat3Y2xR0qpI9Bbqzde/wr0+jqKmU5r6vzYKMV8r9eijmfUxYvfSR2gWzCbtV/u2LzD1fdvHNjYdVE3dXgK12++Hrvftrur76fesf2Skmg1qfOnqKtU7CzqmNTRehs3Ao6ji7pz54BKxd81dUA4Sd3iov7vyLo4d7tdUnf0qP6ZNLagxuRYA7JLpzV1pv2yU8DcTi6nA+hukzpulBIPfid1QPOibn5p3tWaOqD7ou742eN45o1nsH/nfkhE7erE3S8pmfSaOv+SukqlAMdhUUdJIAJs3qyLOnNGnY3tl4uL7l8Zd2q//J3fWb9u7uqr9SWLOvJgZEQXbtVq868vLOinbaqH386plL4Pr1Ps1Cl96ecSWupemEld0EXd1OEppCSFfTft8/y95B/ufklJVL+mzg/l8kUmdZQgExPBFnVhtF8uLLhfmDQ21ryoU6r5zpcAMDCg2y5Z1JEHI7U13K2OGygUeltPZ3TzvsncnB7fBu5hEQtBJXX1h48XS0UslZdcbZQCdFfUVVUVf3vkb3H7NbfjyhEemRkltl9SEvm9pk63X9p18DjAoo5a2bJFH2lgNgHp16RuZkZf36yoA2JzVh3ZwxR1rVowvbwX0U43U2x2dvWYSopeGEmd2cnSzUYpQHdF3U9P/BSvX3idG6TEAIs6SqJ0OgeRDb6uqWP7JSXHli1rkzq/19SFtVGKl6JuYQFYWVl7fatNUoyYnVVH8Teqd4VvWdQVCr1tkmJ0W9TxuML4MEmdeSHuh3VFXVEXdW6TurGBMc9F3dThKYxsGMHd193t6fvIfwPOAAAeaUDJk8mM+9Z+yY1SKFnqi7psVm8U4qewjjTwUtQB63fAdFPUnTy5vhgkaiHMpK5Vi2crTOripVgqQiDIpl1s9uRSY1F3rqjf2faypu7C8gVUVYtFoQ0WVhbwxLEncM8N9/jaRkrdERHknByTOkocxxn38UgDrqmjJNmyRe+7/sYb+lWe37uVhZXUuX11bIq6xhbMl17SX2vVfrp9u97xwuwFT9SBKepaHWuwsBBdUjc3x6IuTorlInKZnK+7RQ5lmrdfellTV1VVFJbdvWPwxLEnsFhaxP5dbL2Mi3wmz6KOEkcndb0XdUpVUK1e8uUQ87CxqKPmTA/WSy/533oJ6Feci4uttwD0g9f2S6B5Udds50vDnFXHFkxyyU37ZRRr6qpVFnVxUywVfV1PB2Dd4eOm/dLLmjoArlswHz/2OK4ZuwZ7t+31OFIKSj6T55EGlDiOM4ZSqff2y0pF/35kUkfJYV7Zvfyy/5ukAKvFVjHAPyy9FnXtdr40eFYdeRTXjVLm5/WRlFxTFx8mqfPTUHYIK5UVrFR0y7hpv/SS1AHui7pDbx3Cre+4lWfTxUguw/ZLSh6/krpyWXchsKij5DCv7FZWginqzKvWINfVeXl13GxN3alTwPnz7Yu6K68EMhkWdeRap6LOr41Shoe9Ta/ZWX3JpC4+imX/k7qhrP6duLii29/nl+YhEIxscNdq5KWoO71wGrOLs9g5ubPL0VIQ2H5JSeTXmrpKRf9xZlFHyVH/dn2QSV2Q6+p6TeqOHtWX7Yq6dBq46ioea0CumfcZmq2pUyq6pG5uTl+yqIuPYimYpA7A5RbMc8Vz2DiwESlx93LAS1E3fXoaALDril3dDJUCwvZLSiLHGUO1uohqtbeN6yqVQu3+uKaOkqK+qAtqTR0QXFJXqQBLS+6LupERIJVaW9R12vnSuOYaJnXkWjqtU7RmSd3ysn7q+rVRSqnkfmNWk9Sx/TI+Ak3qSqtJndvWS8BbUXf49GEAYFIXM9z9kpIok9G/x3o91oDtl5Q8Y2P61SdgZ1Jn7tdt5JFK6WMbGou6zZs7Rxc8q448GhlpXtSZIwj8SuoA9++bsP0yfsJK6txukgJ4TOpmpnHV6FWe7p+Cx/ZLSiLH0UVdry2YJqljUUfJkUoBmzbpj21cU2eKOrdJHaBbMBuLuhtv7Px927cDZ854PxSM+tbISPP2SzMd/Erq6u+zE9N+uXlz749N/ggyqTNF3XzRW1Jn1t65TerYehk/+Uyeh49T4qwmdb0WdfodV8dhUUdJYt6ytzmp67aoUwo4dqxz6yXAHTDJszCTOrfvNczO6vdxHKf3xyZ/hJHUzS/Nuz54HACclIPh7HDHoq5YKuJXZ3/F1ssY4u6XlESOo3+P9XqswWr7JdfUUZKYxTU2rqkz99ttUXfypH7V7aao41l15NHoaPOizjxto2q/5Hq6eAkjqTtXPOcpqQP0mXbnl9sXdUdnj6KqqkzqYijvsP2Skse/pI7tl5REW7YA2axea+a3uK2pA9YWdW43SQGY1JFnrZK6KNsvZ2e5ni5uAjl8PKN/9y6sLEAphfmit6QO0OvqzKHlrZidL5nUxQ93v6Qk8nNNnYiDVGqDH8MKFRttqLXf/V39yjOIQ2PjvqbOS1G3aZP+72FRRy61WlMX5UYpc3Punu4UnqAOHwd0UVdYKaCiKp6Tuo0DGzu2Xx6eOYzh7DC2j23veqwUDNN+qZTiofCUGI4zCkB6TurK5YtIp4etnBtM6qi1P/kT4B/+IZj7juuauvPngWpVF3WTk6ubxbQjotM6nlVHLnVqv/Tr8PH6++yESV38BJLUZVeTOpO2ed2d0k1RN316Gjuv2On6/DsKTz6TBwAslZciHgmRf0RScJyNPR9pUKkUrFxPB7Coo6ik08DAQPBr6ry2XyqlI5SjR73FFjyrjjwYGdFP0Upl7fVRJXXlMnD2LNfUxUlVVbFcWfY9qcums8ims1hYWcC5on5Hu5v2y3ZFXVVVcWTmCFsvY8oUdVxXR0njOOO+tF/auPMlwKKOojQ4GL+kDtDHE7jd+dIwZ9Up5f57qG+N1N4EbCy4otoo5cwZfcmkLj5MiuJ3UgfoFszFlUXML+l3tD23X25oX9S9Ov8qCisFbpISU+Y5xXV1lDSZzLgvG6XYuEkKwKKOojQ0FL81dQAwPa2/32tRd+nS6mFfRG2Yoq5xXV2hsBpi9yqv34x3NcXM05ZFXXyYc8T8TuoAXdQtlOqSui7aLy8uX0RVVZt+nZukxBuTOkoqxxnz4UiDiyzqiDwLMqnr5kiDsdoLm3/6J33ptagDuK6OXBkd1ZeN6+oWFvR7HX6sz06ndWHnpqibndWXbL9sTUQeEZFZETlad92XRORNEZmu/bvTr8czL7iDSurq19R1s1GKgsLF5SYLQ6E3SUlJCjdO3NjzWMl/LOooqfxK6hyHa+qIvAk6qRsY0K9s3TJJXTdFHc+qIw9MUtesqPNjkxTD7RQzRR2TurYeBXBHk+u/qpTaVfv3lF8PZlrjAkvqVhYut192s6YOQMsWzOnT09ixaUcgY6femaLOpMFESeHXmjomdUReDQ4GW9R5SemA1aLu8GFg69bV5M6Nq6/WlyzqyIV27Zd+rKczhoZWN19ph+2XnSmlngbQ26sFDy63XwaY1J0rnkM2nb38It+tTkXd4ZnDXE8XY6bYZlJHSeM4YyiX56FatIa7US6zqCPybmgo2PZLr0WdKeKU8n5g1+CgfkXMoo5caJfU+V3UuU3q0mlv72PQZQ+IyJFae6ZvP8Egk7rBzODl9suxgTHP5zGZNXjNirpzxXN4/cLrLOpijO2XlFSZzDiAKioVF+9mNqGUYlJH1JWgkzqvr44zmdXet25OYeZZdeRSqzV1hUJ07ZebNwMp/kXw6msA3glgF4BTAL7c6oYicr+IHBKRQ3MuNlQKJalbOud5kxRgNakza/LqHZk5AoCbpMTZ5fZL7n5JCeM4uuOq2xbMavUSgCrX1BF5FmRS1037JbDagnljFwv8eVYduRRWUjc87L6oY+uld0qpGaVURelen28AeG+b235dKbVbKbV7i4sdaUJZU1ec97xJCtC+/dLsfMmkLr7MGwVM6ihpdFKHrjdLKZd1wsekjsiroDdK6aWo6zape/11fZJzSERkm4j8REReFpGXROSztesD25WPemcKt8Y1dVFtlDI3x6KuGyKyte7TTwA42uq2XoW1ps7rJilA+6Lu8MxhTA5OYnJosudxUjDi3H7Z5m/auIgcEJHjtUs2i9M6jqOfFt0ea2DaNlnUEXlljjQI4sDubiMPU9TdcIP3792+HahUgJMnvX9v98oAPq+Uuh7A+wB8RkTM4APZlY96l0rp4q1Z+2VUa+pY1LUnIt8G8HMAO0TkpIjcB+C/i8iLInIEwAcB/Ee/Hi/opG5xZRHniue6SupGNoxAIC2TOqZ08Rbz3S9b/U17EMBBpdS1AA7WPidao9ekrlLRf5Qdx86izoka7XoyAAAca0lEQVR6ANTHhoaAahVYWgJyPr9w6Tapm5wE3vGO1UVPXtSfVWd2wwyYUuoU9FoeKKUKIvIygCtDeXDqyehovI404Bl17Sml7m1y9cNBPV7QSZ2CwluFt7pK6lKSwsiGkXVF3UplBcfmjuEj13zEr6FSAOK8+2Wbv2l3AfhA7WZTAH4K4AsRDJFirNc1davtl1xTR+SNKbqCWFfXbVH3l38JPPlkd48Z8Vl1InI1gJsBPFe7KpBd+cgfIyNri7pqtbv9fdpxU9QtL+txMKmLl6CTOgAoVUtdJXWAbsE8v7y2qPvlmV9ipbLCpC7mnJSDTCoTy6KuXsPftMlawWcKP/7GonVM+2X3SR3bL4m6Y169BrGurpsjDQDgqquAm27q7jG3bdP7wkdQ1InIEIAnAHxOKXURLnfl87ojH/lnZGTtmjrz3obfRd3yMlAqtb4Nz6iLp6CTOqOb3S+BWlHXkNRxkxR75DP5WBd1Tf6muf0+/k3rY+n0AFKpHMrl3tbU2dp+yaKOohN0Uufnq2M3HEcXdiEXdSKSgf7j95hS6ruA+135vO7IR/5pbL80h4T73X4JtH/fZHZWX/J/f7yEkdQB6C2payjqDp8+jAFnANduuran8VHwcplcbI80aPY3DcCM2Ziodjnb7Hv5N40cZ7zr9ksmdUTdCiqpW1nRO1B2k9T1KuSz6kSfGvwwgJeVUl+puz6wXfnIH43tl2Ya+J3U1d93M6aoY1IXL8VSEdl0Finx/8/0YGb1d2M3a+qAFkndzDTePfFuOCku14+7uCZ1rf6mAXgSwP7ax/sB/CDssZEdMpnxHo400H+UuaauAbelpY6CSurMK9goirrwz6rbC+BTAG5rOL4gsF35yB+N7ZfmaRt2Usf2y3gqlouBtF4C/rRfjuXG1hR1SikcPn2Yh45bIq5FHVr/TXsIwO0ichzA7bXPidZxnLEejzQQpNMRvH70QZBvp5ltaV8QkWEAvxCRAwD+PfS2tA+JyIPQ29JyB6N+FFRSF8TiJLe2bwdmZoBLl4B8PvCHU0r9DIA0+RKPMIi5xqTOtF8yqSNAJ3VBtF4CPrVfbtiI+eLqC6c3C2/ibPEs19NZIufEs/2yzd80APhQmGMhO2Uy4ygWf9vV91YqBaTTQ9CBsX0CS+qUUqeUUi/UPi4AqN+Wdqp2sykAdwc1Boq5oJI6c39RtV8CwIkT4T82WWV0VD9VKxX9eRDtlyb161TUZbP+JoTUu9CSuh7aLwsrBZSrZQB6PR0A7LyCSZ0NYpzUEfWklzV15XLB2vV0QEhr6rrZlpY7GPWBoJO6KIu6ENfVkZ1Gai37JqGLcqOUiQnA0jcmE6tYDiep62X3SwC4uKzjZrPz5U2TXe4eTKFiUUdJ1cuaukrlIhzHzvV0QAhFXbfb0nIHoz6Q1DV1QGRn1ZE9TFFn1tVFtVHK3BxbL+OoWAo+qRvMDCKbznZ1H6aoM+vqDs8cxjvH3omRDfa+IOon+Uz+8rEZREniOGOoVouoVJY8f69uv2RS11Qv29JSHzBFV5LW1E1M6LV0LOqoA1PUmXV1UW2UYpI6ipcgk7pcJgeBdL2eDlhf1E2fnmbrpUVymRyTOkokx9G/17o5q47tly1wW1rqKJsFMplkrakTAa6+mkUddTQ6qi9NURflRilshoifIJO6lKQwmB3suvUSWFvULaws4DfnfoNdk9wkxRZ5h+2XlEyZjCnqvLdgMqlrjdvSUmdDQ/4ndVG2XwKhn1VHdmqW1A0M6DPs/eImDGdSF09BJnWAbsH0K6l7ceZFKCgmdRbJZ/Kx3P2SqFeOo9+s6uZYA72mzt6iLrAjDbgtLbkyOBhcUhdF+yWg19U9/TSgFHefoJYa19QVCv4/ZR1HF4omBWy0uAgUiyzq4ijIpA4AhrPDvhV1MwszAMDjDCzC9ktKql6SOt1+ae+64CDPqSPqLIikLsr2S0AndYUCcO4csGlTNGOg2Gtsv1xYCOZ9iHZTzJxRx/bL+Ak6qfvrj/01tgx2/z++vqj79dlfY+PARmwb2ebX8Chg+Uwe5WoZpUoJmXQm6uEQ+casqevmWAPb2y9Z1FG0gkrqRIBccC+I2jLHGrz6Kos6aqmx/bJQCOasODdFHZO6+Ak6qfvov/poT98/vGEYKUnh/NJ5TJ+exq4rdll7YG8/ymfyAPSbByzqKEm6Teqq1WUotWJ1+2Uo59QRtRTUmrrBwehaH3fsAG67LZrHJmuYp2j9kQZBJHXDw62nmDkClEVd/AR5+LgfUpLC6IZRnL10Fi/Ovoidk1xPZxPz3GILJiWNTtpSnne/LJcLdd9vJyZ1FK3BQeD0aX/vc3ExutZLALj+euDgwegen6yQSumCq779ciSAVn4mdfZRSumkLsD2Sz9sHNiI5996HpdKl7iezjImqWNRR0kjkoLjjHluv6xUTFFn75o6JnUUraGhYNovoyzqiFwaHV3bfsk1dQQAK5UVKKhYJ3WALupeOPUCAG6SYhsWdZRkmcy45/ZLU9Sx/ZKoW4ODwbVfEsXcyEj0G6UMDgL5vP+PS90zW83bkNRVVAVOysH1m6+PejjkgXluFUs81oCSRyd13tovV5M6FnVE3QkqqYvqOAMiD0ZG1h5pEPZGKXNzbL2MI/NC24akDgBu2HIDNjgbIh4NecGkjpKsm6SuXNbvsLKoI+pWEEkd2y/JEnFI6th6GT82JXUAuEmKhVjUUZI5znjXa+och2vqiLozNASUy8DKin/3yfZLsoRZU7eyov8FldS1Onx8dpZJXRzZltRxPZ196o80IEqaXtbUMakj6paJJvxM69h+SZYwSZ15+geV1C0t6fdOGrGoiycmdRQ0HmlASeY4YyiXz0OpquvvScKRBizqKFomUfNzXR3bL8kSZk2dKeqCSuqA9VNMKa6piyuT1Jk0Ja6uGbsG+UweN2+9OeqhkEdsv6Qkc5xxAArl8gXX31OpcE0dUW+CSupY1JEFRkeBS5eA+domXUEdPg6sn2IXLgClEtfUxdHlpC7m7Zf33ngvTnz2BMZz41EPhTy63H7J3S8pgTIZ/TvJSwtmpVJAKpVDKmXvEd4s6ihafid1SrH9kqxhDhs/dUpfBtV+Cawv6njwuDci8oiIzIrI0brrxkXkgIgcr12O+fFYl9fUxbz9Mp1KY8sg3xWwkXluMamjJHIc/avYy7EG5XLB6pQOYFFHUfM7qSsWdWHHpI4sYIq6N9/Ul0G2XzZOsbk5fcmizrVHAdzRcN2DAA4qpa4FcLD2ec9sSerIXhvSGyAQFnWUSN0mdSzqiHrhd1Jn7odFHVmgsahjUhdfSqmnATS+QrgLwFTt4ykAd/vxWLYkdWQvEUE+k+ful5RIek0dPB1rUKlchOOwqCPqnt9JnbkfFnVkgdFRffnWW/oyzKTOFHVcU9eTSaXUKQCoXfpSIjOpozDkMjkmdZRI3SR1uv3S3jPqABZ1FLWgkjquqSMLxCGpY1EXDhG5X0QOicihOdP72gKTOgpDPpNnUUeJZNbUlcvu19Sx/ZKoV34ndWy/JItEWdTNzQEbNwLZrP+P2UdmRGQrANQuZ1vdUCn1daXUbqXU7i0dKmkmdRQGFnWUVKlUFqnUoMf2ywLbL4l64ndSx/ZLskh9UScC5AM4lswUdYXC2utnZ5nS+eBJAPtrH+8H8AM/7rRYKiItaWTSGT/ujqipnJPjmjpKrExm3GP75UUmdUQ92bABSKf9T+rYfkkWMGvqZmf1+xCpAH4jm/c3mrVfcpMU90Tk2wB+DmCHiJwUkfsAPATgdhE5DuD22uc9K5aLbL2kwDGpoyRznDFPRxro9ku719TZe8IeJYOIftXZKal77DH9Cvj3f7/97dh+SRYZHNRTQKlgNkkBdHtlNtu8qHvXu4J5zCRSSt3b4ksf8vuxiqUiWy8pcPlMHoWVQucbElnIS1KnVAXV6iW2XxL1bGiofVI3NQXs2wd84Qud76vPijoR2SYiPxGRl0XkJRH5bO36QA5FJn+JrLZgBhkuDw83X1PHpC6emNRRGHKZ3OVNeYiSxnHGXa+pq1T0H0i2XxL1ql1S98MfAvfdp29z7Bgw3yFK7781dWUAn1dKXQ/gfQA+IyI3IKBDkcl/pqgLKqkD1r9vUqkAZ85wTV1cFctM6ih4bL+kJPOS1JXLFwGwqCPqXauk7plngHvuAXbtAr71LX3ds8+2v68+W1OnlDqllHqh9nEBwMsArkRAhyKT/8y6uiCfso1T7Nw5oFplUhdXxRKTOgpe3mFRR8nlOGOujzSoVAq177F7TR2LOopes6TupZf0+rm3vx146ingttv0hirPPNP+vhYXAcfpy33aReRqADcDeA4uD0X2cnYWBSOM9svGos6cUceiLp6Y1FEY8pk8d7+kxHKccVSrS6hUOj/HTVHHpI6oV42vOF9/HfjoR/XOmD/+sX7lOTQE7NzZuahbWOin1svLRGQIwBMAPqeUuuj2+7ycnUXBiKL90tTvLOriiUkdhSGXyTGpo8TKZMYBwFULZrnMoo7IH4ODq684z5zRBd3Cgi7otm9fvd2ePcBzzwHlcuv7Wlzsm9ZLQ0Qy0AXdY0qp79audn0oMkUrivZLk9Sxjo8nJnUUhnwmj6XyEqqqGvVQiHznOHp/ODfHGjCpI/LL0JAuxhYXdcvlq68CTz4J3HTT2tvt2aNvc+RI6/taXOyrpE5EBMDDAF5WSn2l7kuBHIpM/gsrqas/fJztl/HGpI7CkM/kAQBL5aWIR0LkPy9JXaWiG5y4po6oV4ODwIULwCc/CTz/PPCd7wC33rr+dnv36st2LZj91365F8CnANwmItO1f3cioEORyX9RrKmbm9PHKWzaFNxjUveY1FEYzHOMLZiURI6jizo3xxokpf2Sh49T9IaGdFH3ox8B3/gGcHeLjRq3bQOuvFIXdQ880Pw2fdZ+qZT6GQBp8WXfD0Um/0W1UcqmTXrvIYofHj5OYTBJHYs6SiJvSV0yijomdRQ9s6joL/4C+PSnW99ORLdgtkvq+qz9kuxnnv5Btl8ODwOXLunz6QBd1LH1Mr54+DiFwRR1PICcksisqXNzrEGlUoCIg1RqQ9DDChSLOoreffcBf/d3wBe/2Pm2e/YAr70GvPlm86+zqCPLhJXUAbqwA1jUxR2TOgqDeeOASR0lkU7d0i7bLy8inR6B3qbAXizqKHqTk3o9nZvJtGePvmyV1vXfmjqyXFgbpQCrLZhzcyzq4qpcLaNULTGpo8DFsf1SRB4RkVkROVp33biIHBCR47XLsSjHSHYQEWQy467bL21vvQRY1JFtbr4ZyOVaF3V9tqaO7Ldxo74Ms6ibneVxBnFlWuGY1FHQ4ljUAXgUwB0N1z0I4KBS6loAB2ufE3XkOGOujzRwHBZ1ROHKZIBbbmlf1DGpI4vceivwV38F/N7vBfcY9UXdygowP8+kLq6K5VpRx6SOAmbeODDPuThQSj0NoDFauQvAVO3jKQAtdlMjWotJHVHc7dkDvPACUGz4Q1SpAEtLLOrIKpkM8Kd/qi+DUl/UnTmjP2ZRF09M6igsMU3qmplUSp0CgNolf3uRKwMD27Gw8C+oVkttb6fX1LGoIwrfnj1AuQwcOrT2+sVFfcn2S6I16ou6uTn9MYu6eGJSR2GxqKhzTUTuF5FDInJozvyyo741MfFvUCqdwfz8gba30+2Xdh88DrCoIxu9//368p//ee31pqhjUke0hinqCgW9ng7gmrq4YlJHYTFvHFhwpMGMiGwFgNrlbKsbKqW+rpTarZTavYW/5Pre+PjH4DjjmJn5Ztvbsf2SKCqbNwM7dqxfV2d2gWBRR7RGfVJnijomdfHEpI7CYlFS9ySA/bWP9wP4QYRjIYukUllMTNyDM2e+j3K50PJ25TKLOqLomEPIlVq9jkkdUVNmZ022X8YfkzoKi3mOxamoE5FvA/g5gB0iclJE7gPwEIDbReQ4gNtrnxO5Mjm5D9VqEWfOfK/p15VSTOqIIrVnD3D2LHD8+Op1XFNH1FRjUuc4q0cpULwwqaOwpFNpbEhviNvul/cqpbYqpTJKqbcrpR5WSp1VSn1IKXVt7bLzdoZENSMjezAwcHXLFsxq9RKAKtfUEUWm2SHkTOqImspm9e6apqjbsgUQiXpU1AyTOgpTLpOLVVJH5DcRweTkPszPH8Ty8lvrvm7aMpnUEUXluut01FC/WQrX1BG1NDS0WtSx9TK+mNRRmPKZPIs6SryJiX8LoIrZ2e+s+1qlwqKOKFqp1Oq6OoPtl0QtmaJubo5FXZwxqaMw5TP5WLVfEgVhcPA6DA/vbtqCWalcBAA4Dos6oujs2QMcOwbMz+vP2X5J1FJ9UsedvuOLSR2FKeew/ZL6w+TkPiws/AsWF4+tuX61/ZJr6oiiY9bVPfusvmT7JVFLbL+0A5M6ChPbL6lfTEz8IYA0ZmYeW3M92y+J4uCWW4B0erUFk0kdUUtDQ7qgW1hgUec3ETkhIi+KyLSIHOrlvkxSN+AM+DI2onbymbwNh48T9SybncTY2IcxM/MYlKpevt4UdWy/JIrS0BCwc+faom5gQBd6RLTG0BDw6qv6Y7ZfBuKDSqldSqndvdxJsVTEgDMA4fakFALufkn9ZHJyH5aXX8OFC6ub7JXLek0dkzqiqO3dCzz3HFAu66KOKR1RU8PDwLna6U5M6uKrWC6y9ZJCw/ZL6iebN9+NVCq/ZsOU1fZLrqkjitaePbqYO3JE95WxqCNqqn5TWBZ1vlMA/lFEfiEi9ze7gYjcLyKHROTQ3NxcyzsqlorcJIVCw6KO+onjDGHz5k9gbu5xVKvLAExRJ0in7X/9yKKO7FZ/CPniIo8zIGqBRV2g9iql3gPgYwA+IyK3Nt5AKfV1pdRupdTuLW36X5nUUZhyTo5HGlBfmZzch3L5PM6efQqALurS6aFEtLwHVtSJyCMiMisiR+uuGxeRAyJyvHY5FtTjU5/Ytg248srVoo5JHVFT9UUd19T5Syn1Vu1yFsD3ALy32/sqlpnUUXiY1FG/GRv7MDKZicstmOXyxUSspwOCTeoeBXBHw3UPAjiolLoWwMHa50TdE1k9hJztl0QtmaJuYICBtp9EZFBEhs3HAD4C4Gj772qtWGJSR+ExRZ1SKuqhEIUilXIwMXEvzp79IUqleVQqBTiO/evpgACLOqXU0wDONVx9F4Cp2sdTAO4O6vGpj+zdC7z2GnD8OF+tErVgpsbEhH4vhHwzCeBnInIYwP8D8H+UUj/q9s6Y1FGYck4OVVVFqVqKeihEoZmc3AelVjA39/e19stkJHVOyI83qZQ6BQBKqVMiwpUd1Duzrm5mhkkdUQv1RR35Ryn1CoCdft1fsVTEeG7cr7sjaiufyQMALpUuIZvORjwaonAMD/9r5HI7amfWlRNT1MV2oxS3O4URYdcuIFd7Z5tFHVFTpqjjerp4Y1JHYaov6oj6hYhgcnIfLlz4vygWf82irkszIrIVAGqXs61u6HanMCJkMsAtt+iPWdQRNcWkzg5cU0dhMkVdscQdMKm/TE7+EQCgVJrjmrouPQlgf+3j/QB+EPLjU1KZFsw+XFPXYqfZL4nImyIyXft3Z5RjpOixqLMDjzSgMJlUmEkd9Ztc7hqMjOjXjklJ6gJbUyci3wbwAQCbReQkgD8H8BCAx0XkPgCvA/iDoB6f+szevfqyP5O6RwH8TwB/03D9V5VS/yP84VAcDdf+ZrHxId54+DiFySR1P/7tj/Hq+Vdb3i4taXz8XR8Pa1hEoZic3IeLF59hUdeJUureFl/6UFCPSX3s/e/XBd1VV0U9ktAppZ4WkaujHgfF2+QkkM0C110X9UioHSZ1FKYrhq4AAPzZgT9re7t8Jo/FLy6GMSSi0ExM3INXXvnPGBhIxmvHsHe/JArGpk3AiRPAGM+zr/OAiPw7AIcAfF4pNR/1gCg6W7YAJ08CmzdHPRJq59n7nuXulxSa92x9D371wK+wsLLQ9nYpie2+ekRdy2Q24X3vO4F0ejTqofiCRR0lB1+t1vsagP8KQNUuvwzgPzTeSETuB3A/AFzVhylnv2HrZfztvMK30xGIXHnXpndFPQSiyGQym6Iegm/41gtRAimlZpRSFaVUFcA3ALy3xe24yywRERGR5VjUESWQOTqk5hMAjra6LRERERHZje2XRJZrsdPsB0RkF3T75QkAfxzZAImIiIgoUCzqiCzXYqfZh0MfCBERERFFgu2XREREREREFmNRR0REREREZDEWdURERERERBZjUUdERERERGQxFnVEREREREQWY1FHRERERERkMVFKRT2GjkRkDsBrbW6yGcCZkIbjB5vGa9NYAbvG+w6l1JaoB2FwnkXOpvHaNNZYzTMgcXPNprECdo3XprFyngXPpvHaNFbArvG2nGtWFHWdiMghpdTuqMfhlk3jtWmsgH3jtYltP1uONzg2jdVGNv18bRorYNd4bRqrjWz7+do0XpvGCtg33lbYfklERERERGQxFnVEREREREQWS0pR9/WoB+CRTeO1aayAfeO1iW0/W443ODaN1UY2/XxtGitg13htGquNbPv52jRem8YK2DfephKxpo6IiIiIiKhfJSWpIyIiIiIi6kvWF3UicoeI/EpEfiMiD0Y9nnZE5ISIvCgi0yJyKOrxNBKRR0RkVkSO1l03LiIHROR47XIsyjEaLcb6JRF5s/bznRaRO6McY5LYNM+AeM81m+YZwLkWJs4zf9k01zjPwmXTXOM880/S55nVRZ2IpAH8LwAfA3ADgHtF5IZoR9XRB5VSu2K6deqjAO5ouO5BAAeVUtcCOFj7PA4exfqxAsBXaz/fXUqpp0IeUyJZOs+A+M61R2HPPAM410LBeRaIR2HPXHsUnGehsHSucZ7541EkeJ5ZXdQBeC+A3yilXlFKrQD4DoC7Ih6TtZRSTwM413D1XQCmah9PAbg71EG10GKsFAzOMx/ZNM8AzrUQcZ75zKa5xnkWKs41H3GexYftRd2VAN6o+/xk7bq4UgD+UUR+ISL3Rz0YlyaVUqcAoHY5EfF4OnlARI7UIvZYxP0JYNs8A+yba7bNM4BzzW+cZ+Gwba5xnvnPtrnGeRa8RMwz24s6aXJdnLfz3KuUeg905P8ZEbk16gElzNcAvBPALgCnAHw52uEkhm3zDOBcCxrnmv84z6gR51kwbJtrnGfBSsw8s72oOwlgW93nbwfwVkRj6Ugp9VbtchbA96BbAOJuRkS2AkDtcjbi8bSklJpRSlWUUlUA34AdP18bWDXPACvnmjXzDOBcCwjnWTismWucZ4Gxaq5xngUrSfPM9qLueQDXish2EckC+EMAT0Y8pqZEZFBEhs3HAD4C4Gj774qFJwHsr328H8APIhxLW+YXSM0nYMfP1wbWzDPA2rlmzTwDONcCwnkWDmvmGudZYKyZa5xnwUvSPHOiHkAvlFJlEXkAwI8BpAE8opR6KeJhtTIJ4HsiAuif+7eUUj+Kdkhrici3AXwAwGYROQngzwE8BOBxEbkPwOsA/iC6Ea5qMdYPiMgu6DaKEwD+OLIBJohl8wyI+VyzaZ4BnGth4Tzzn01zjfMsPJbNNc4zHyV9nolScW4jJiIiIiIionZsb78kIiIiIiLqayzqiIiIiIiILMaijoiIiIiIyGIs6oiIiIiIiCzGoo6IiIiIiMhiLOqIiIiIiIgsxqKOiIiIiIjIYizqiIiIiIiILPb/Ac95T7LWCpWWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = list(range(0,20))\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "ax1.plot(y,listList[0],'r-')\n",
    "ax2.plot(y,listList[1], 'b-')\n",
    "ax3.plot(y,listList[2], 'g-')\n",
    "ax4.plot(y,listList[3], 'y-')\n",
    "\n",
    "ax1.title.set_text(tecList[0])\n",
    "ax2.title.set_text(tecList[1])\n",
    "ax3.title.set_text(tecList[2])\n",
    "ax4.title.set_text(tecList[3])\n",
    "\n",
    "ax1.set_ylabel('%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After playing around with the best performance of the combination of the value of C and the kind of regularization I recieved that the Newton's method is defefnetly the best, with it best performance when eta = 0.1, number of iterations = 2 , we recieved accuracy of 56.83 %.\n",
    "However, the accuracy is still low.\n",
    "\n",
    "Let's check how SKlearn algorithm for the logistic regression will perform on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of:  0.5428571428571428\n",
      "Wall time: 24 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "\n",
    "lr_sk = SKLogisticRegression(solver='liblinear')\n",
    "\n",
    "lr_sk.fit(X_train,Y_train)\n",
    "yhat = lr_sk.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(Y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn performe a little worse than the Newton's method, but still better than all the other optimizattion techniques. Now, let's run again the best performance from above and see its performance time:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of:  0.5682539682539682\n",
      "Wall time: 88 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LR(0.1, 2, C=0.01, Reg = 'L1L2',optTec = 'newtons')\n",
    "lr.fit(X_train,Y_train)\n",
    "yhat = lr.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(Y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2.6% between our Newton's method and the sklearn implementation cost us increasing in running time. Actually, our implementation is 4 time slower than sklearn. For this size of data set I would say it does not that effective, but for larger set it will definitely make a big different.\n",
    "\n",
    "If we summarize the comparison section, we can conclude that overall the sklearn implementation is better than our best implementation  the Newtons method. However, if we will need to use this model in order to make the product we claim at the beginning, both models are way off from the main goal of the product. We were talking at the beginning about accuracy percentage above 90%, and our best implementation is not even 60%. If we would be able to find better data set, with more variety of quality level as well as bigger sample, we may could build a better model. In different case, we may need to find different features in order to predict better the wine quality level. In these cases, I would recommend using the sklearn implementation as soon it stands with our standard of more than 90% accuracy, because it is faster than our implementation. However, in our situation right now, I would not recommend using any kind of model from the ones we checked above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work\n",
    "\n",
    "**Buiulding Mean Square Error based model**\n",
    "\n",
    "For Implementing an optimization technique for logistic regression using mean square error as my objective function, we will use the function J = (y-yhat)^2, where yhat is W.T@X, so we will have the fucntion J(W) = (y - W.T@X)^2. in order to find the best W values, we will search for the minimum point of the function, so we will take the derivitive of that and compare it to 0.\n",
    "After doing the calculation, we will get that W = ((X.T@X)^-1)X.T@y\n",
    "Once we will have W, we can predict y, which will be yhat. The last step is taking yhat through the sigmoid funtion and predict for 1 or 0.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BinaryMSE: \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return expit(theta) \n",
    "    \n",
    "    def _get_w(self,X,y):\n",
    "        return ((X.T@X)**-1)@X.T@y\n",
    "    \n",
    "    def predict_proba(self, X, add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "\n",
    "    def fitBinary(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        self.w_ = self._get_w(Xb,y) \n",
    "\n",
    "class MSE:\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = (y==yval) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = BinaryMSE()\n",
    "            blr.fitBinary(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            pred = blr.predict_proba(X)\n",
    "            pred = pred.reshape((pred.shape[0],1)) #fixing the size since get (N,) instead of (N,1)\n",
    "            probs.append(pred)\n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of:  0.4031746031746032\n",
      "Wall time: 9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mse = MSE()\n",
    "mse.fit(X_train,Y_train)\n",
    "yhat = mse.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(Y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this way is actually the worst amoung all of our implamentations as well as sklearn, however it is the fastest. Considering the performance of all the other techniques on this spesific data, I will consider this way as acceptable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
